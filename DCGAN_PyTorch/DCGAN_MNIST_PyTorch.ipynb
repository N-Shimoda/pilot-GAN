{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7004,
     "status": "ok",
     "timestamp": 1627794892134,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "_5nZnnI0zqJX",
    "outputId": "ebdcf056-eef7-4a1d-e3e4-7e5b60744f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. データセットとデータローダーを用意\n",
    "'''\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# MNISTデータセットの訓練データを用意\n",
    "dataset = datasets.MNIST(\n",
    "    # mnistフォルダーに保存\n",
    "    # パスは環境に合わせて書き換えることが必要\n",
    "    # root='/content/drive/MyDrive/Colab Notebooks/GAN/DCGAN_PyTorch/mnist',\n",
    "    root=\"mnist\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    # トランスフォームオブジェクトを設定\n",
    "    transform=transforms.Compose(\n",
    "        # Tensorオブジェクトに変換\n",
    "        [transforms.ToTensor(),\n",
    "         # データを平均0.5、標準偏差0.5の標準正規分布で正規化\n",
    "         # チャネル数は1なのでタプルの要素も1\n",
    "         transforms.Normalize((0.5,), (0.5,))]\n",
    "         )\n",
    "    )\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size=50\n",
    "\n",
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size, # ミニバッチのサイズは50\n",
    "    shuffle=True,          # データをシャッフルしてから抽出\n",
    "    )\n",
    "\n",
    "# 使用可能なデバイスを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0Th2mvrs1Qc5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "2. 識別器のクラスを定義 \n",
    "'''\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    '''識別器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''識別器のネットワークを構築する\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        in_ch = 1      # 入力画像のチャネル数\n",
    "        start_ch = 128 # 先頭層の出力チャネル数\n",
    "\n",
    "        # 識別器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList([\n",
    "            # 第1層: (bs, 1, 28, 28) -> (bs, 128, 14, 14)\n",
    "            nn.Sequential(\n",
    "                # 畳み込み\n",
    "                nn.Conv2d(in_ch,    # 入力のチャネル数は1\n",
    "                          start_ch, # フィルター数は128\n",
    "                          4,  # 4×4のフィルター\n",
    "                          2,  # ストライドは2\n",
    "                          1), # 上下左右にサイズ1のパディング\n",
    "                # LeakyReLU関数を適用\n",
    "                # 論文に従って負の勾配を制御する係数を\n",
    "                # 0.2(デフォルトは0.01)に設定\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ), \n",
    "            # 第2層: (bs, 128, 14, 14) -> (bs, 256, 7, 7)\n",
    "            nn.Sequential(\n",
    "                # 畳み込み\n",
    "                nn.Conv2d(start_ch,     # 入力のチャネル数は128\n",
    "                          start_ch * 2, # フィルター数は128×2\n",
    "                          4,  # 4×4のフィルター\n",
    "                          2,  # ストライドは2\n",
    "                          1), # 上下左右にサイズ1のパディング\n",
    "                # 出力値を正規化する(チャネル数は128×2)\n",
    "                nn.BatchNorm2d(start_ch * 2),\n",
    "                # LeakyReLU関数を適用\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ),\n",
    "            # 第3層: (bs, 256, 7, 7) -> (bs, 512, 3, 3)\n",
    "            nn.Sequential(\n",
    "                # 畳み込み\n",
    "                nn.Conv2d(start_ch * 2, # 入力のチャネル数は128×2\n",
    "                          start_ch * 4, # フィルター数は128×4\n",
    "                          3,  # 3×3のフィルター\n",
    "                          2,  # ストライドは2\n",
    "                          0), # パディングは0(なし)\n",
    "                # 出力値を正規化する(チャネル数は128×4)\n",
    "                nn.BatchNorm2d(start_ch * 4),\n",
    "                # leaky ReLU関数を適用\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ),\n",
    "            # 第4層: (bs, 512, 3, 3) -> (bs, 1, 1, 1)\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(start_ch * 4, # 入力のチャネル数は128×4\n",
    "                          1,  # フィルター数は1\n",
    "                          3,  # 3×3のフィルター\n",
    "                          1,  # ストライドは1\n",
    "                          0), # パディングは0(なし)\n",
    "                # 最終出力にはシグモイド関数を適用\n",
    "                nn.Sigmoid()\n",
    "            )    \n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          x: 画像データまたは生成画像\n",
    "        '''\n",
    "        # 識別器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # 出力されたテンソルの形状をフラット(bs,)にする\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oCOCFhI20lmO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "3. 生成器のクラスを定義\n",
    "'''\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    '''生成器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''生成器のネットワークを構築する\n",
    "        '''\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        input_dim = 100 # 入力データの次元\n",
    "        out_ch = 128    # 最終層のチャネル数\n",
    "        img_ch = 1      # 生成画像のチャネル数\n",
    "\n",
    "        # 生成器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList([\n",
    "            # 第1層: (bs, 100, 1, 1) -> (bs, 512, 3, 3)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_dim,  # 入力のチャネル数は100\n",
    "                                   out_ch * 4, # フィルター数は128×4\n",
    "                                   3,          # 3×3のフィルター\n",
    "                                   1,          # ストライドは1\n",
    "                                   0),         # パディングは0(なし)\n",
    "                # 出力値を正規化する(チャネル数は128×4)\n",
    "                nn.BatchNorm2d(out_ch * 4),\n",
    "                # ReLU関数を適用\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            # 第2層: (bs, 512, 3, 3) -> (bs, 256, 7, 7)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_ch * 4, # 入力のチャネル数は128×4\n",
    "                                   out_ch * 2, # フィルター数は128×2\n",
    "                                   3,          # 3×3のフィルター\n",
    "                                   2,          # ストライドは2\n",
    "                                   0),         # パディングは0(なし)\n",
    "                # 出力値を正規化する(チャネル数は128×2)\n",
    "                nn.BatchNorm2d(out_ch * 2),\n",
    "                # ReLU関数を適用\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            # 第3層: (bs, 256, 7, 7) -> (bs, 128, 14, 14)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_ch * 2, # 入力のチャネル数は128×2\n",
    "                                   out_ch,     # フィルター数は128\n",
    "                                   4,          # 4×4のフィルター\n",
    "                                   2,          # ストライドは2\n",
    "                                   1), # 上下左右にサイズ1のパディング\n",
    "                # 出力値を正規化する(チャネル数は128)\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                # ReLU関数を適用\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            # 第4層: (bs, 128, 14, 14) -> (bs, 1, 28, 28)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_ch, # 入力のチャネル数は128\n",
    "                                   img_ch, # フィルター数は1\n",
    "                                   4,      # 4×4のフィルター\n",
    "                                   2,      # ストライドは2\n",
    "                                   1), # 上下左右にサイズ1のパディング\n",
    "                # Tanh関数を適用\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def forward(self, z):\n",
    "        '''順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          z: 識別器の出力\n",
    "        '''\n",
    "        # 生成器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TZFR5dh_0r0W"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "4. 重みの初期化を行う関数\n",
    "'''\n",
    "def weights_init(m):\n",
    "    '''\n",
    "    DCGANの論文では重みを正規分布からサンプリングした値で初期化している\n",
    "    \n",
    "    Parameters:\n",
    "      m: ネットワークのインスタンス\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    # 畳み込み層の重み\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02) # 平均0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0) # バイアスのみ0で初期化\n",
    "    # バッチ正規化層の重み\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02) # 平均1.0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0) # バイアスのみ0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12268,
     "status": "ok",
     "timestamp": 1627794904398,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "rIjYwm-W0zeY",
    "outputId": "06a0da9a-460c-4321-9172-a385225a5213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 3, 3]         461,312\n",
      "       BatchNorm2d-2            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-3            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 7, 7]       1,179,904\n",
      "       BatchNorm2d-5            [-1, 256, 7, 7]             512\n",
      "              ReLU-6            [-1, 256, 7, 7]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 14, 14]         524,416\n",
      "       BatchNorm2d-8          [-1, 128, 14, 14]             256\n",
      "              ReLU-9          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-10            [-1, 1, 28, 28]           2,049\n",
      "             Tanh-11            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 2,169,473\n",
      "Trainable params: 2,169,473\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 8.28\n",
      "Estimated Total Size (MB): 9.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "5. 生成器をインスタンス化して重みを初期化する\n",
    "'''\n",
    "import torchsummary\n",
    "\n",
    "# 生成器Generator\n",
    "generator = Generator().to(device)\n",
    "# 重みを初期化\n",
    "generator.apply(weights_init)\n",
    "# 生成器のサマリを出力\n",
    "torchsummary.summary(generator,\n",
    "                     (100, 1, 1))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1627794904399,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "4sSG9vr8044E",
    "outputId": "5a4d918a-f443-4b83-b2d5-fa12268d3462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 14, 14]           2,176\n",
      "         LeakyReLU-2          [-1, 128, 14, 14]               0\n",
      "            Conv2d-3            [-1, 256, 7, 7]         524,544\n",
      "       BatchNorm2d-4            [-1, 256, 7, 7]             512\n",
      "         LeakyReLU-5            [-1, 256, 7, 7]               0\n",
      "            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "         LeakyReLU-8            [-1, 512, 3, 3]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           4,609\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,713,025\n",
      "Trainable params: 1,713,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.78\n",
      "Params size (MB): 6.53\n",
      "Estimated Total Size (MB): 7.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "6. 識別器をインスタンス化して重みを初期化する\n",
    "'''\n",
    "# 識別器Discriminator\n",
    "discriminator = Discriminator().to(device)\n",
    "# 重みの初期化\n",
    "discriminator.apply(weights_init)\n",
    "# 識別器のサマリを出力\n",
    "torchsummary.summary(discriminator,\n",
    "                     (1, 28, 28))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fxL2WFs_0_cb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "7. 損失関数とオプティマイザーの設定\n",
    "'''\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数はバイナリクロスエントロピー誤差\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 識別器のオプティマイザ−を設定\n",
    "optimizer_ds = optim.Adam(discriminator.parameters(),\n",
    "                          # デフォルトの学習率0.001を論文で提案されている\n",
    "                          # 0.0002に変更\n",
    "                          lr=0.0002,\n",
    "                          # 指数関数的減衰率としてデフォルトの(0.9, 0.999)\n",
    "                          # のβ1の値のみ論文で提案されている(0.5, 0.999)に変更\n",
    "                          betas=(0.5, 0.999)\n",
    "                          )\n",
    "\n",
    "# 生成器のオプティマイザーを設定\n",
    "optimizer_gn = optim.Adam(generator.parameters(),\n",
    "                          lr=0.0002,\n",
    "                          betas=(0.5, 0.999)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1CdrKteQGHGB"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "8. エポックごとの画像生成に使用するノイズのテンソルを作成\n",
    "'''\n",
    "gn_input_dim = 100  # 生成器に入力するノイズの次元\n",
    "\n",
    "# エポックごとに出力する生成画像のためのノイズを生成\n",
    "# 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size,   # バッチサイズ\n",
    "    gn_input_dim, # ノイズの次元100\n",
    "    1,            # 1\n",
    "    1,            # 1\n",
    "    device=device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606572,
     "status": "ok",
     "timestamp": 1627795510955,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "JFzFivDX1D_8",
    "outputId": "5e54e43d-b030-4407-a6db-e2dbaab66870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(1/1200) ds_loss: 1.623 - gn_loss: 2.885 - true_out: 0.466 - fake_out: 0.501>>0.066\n",
      "(101/1200) ds_loss: 0.197 - gn_loss: 4.301 - true_out: 0.935 - fake_out: 0.107>>0.017\n",
      "(201/1200) ds_loss: 0.647 - gn_loss: 4.891 - true_out: 0.772 - fake_out: 0.241>>0.011\n",
      "(301/1200) ds_loss: 0.482 - gn_loss: 5.306 - true_out: 0.957 - fake_out: 0.302>>0.009\n",
      "(401/1200) ds_loss: 0.353 - gn_loss: 3.785 - true_out: 0.929 - fake_out: 0.217>>0.033\n",
      "(501/1200) ds_loss: 0.312 - gn_loss: 2.798 - true_out: 0.875 - fake_out: 0.144>>0.086\n",
      "(601/1200) ds_loss: 0.912 - gn_loss: 2.439 - true_out: 0.558 - fake_out: 0.060>>0.151\n",
      "(701/1200) ds_loss: 0.578 - gn_loss: 2.443 - true_out: 0.811 - fake_out: 0.257>>0.113\n",
      "(801/1200) ds_loss: 0.354 - gn_loss: 2.657 - true_out: 0.840 - fake_out: 0.147>>0.089\n",
      "(901/1200) ds_loss: 0.912 - gn_loss: 0.908 - true_out: 0.625 - fake_out: 0.223>>0.451\n",
      "(1001/1200) ds_loss: 0.401 - gn_loss: 3.863 - true_out: 0.935 - fake_out: 0.254>>0.029\n",
      "(1101/1200) ds_loss: 0.540 - gn_loss: 1.244 - true_out: 0.640 - fake_out: 0.043>>0.334\n",
      "Epoch 2/10\n",
      "(1/1200) ds_loss: 0.784 - gn_loss: 2.187 - true_out: 0.784 - fake_out: 0.358>>0.143\n",
      "(101/1200) ds_loss: 0.496 - gn_loss: 2.197 - true_out: 0.839 - fake_out: 0.240>>0.135\n",
      "(201/1200) ds_loss: 0.795 - gn_loss: 1.955 - true_out: 0.755 - fake_out: 0.351>>0.167\n",
      "(301/1200) ds_loss: 0.492 - gn_loss: 2.532 - true_out: 0.952 - fake_out: 0.331>>0.096\n",
      "(401/1200) ds_loss: 0.301 - gn_loss: 2.879 - true_out: 0.925 - fake_out: 0.182>>0.069\n",
      "(501/1200) ds_loss: 0.370 - gn_loss: 2.977 - true_out: 0.882 - fake_out: 0.182>>0.071\n",
      "(601/1200) ds_loss: 0.633 - gn_loss: 0.937 - true_out: 0.638 - fake_out: 0.125>>0.421\n",
      "(701/1200) ds_loss: 0.641 - gn_loss: 2.442 - true_out: 0.808 - fake_out: 0.277>>0.113\n",
      "(801/1200) ds_loss: 0.907 - gn_loss: 1.592 - true_out: 0.686 - fake_out: 0.345>>0.252\n",
      "(901/1200) ds_loss: 0.230 - gn_loss: 2.714 - true_out: 0.894 - fake_out: 0.100>>0.109\n",
      "(1001/1200) ds_loss: 0.411 - gn_loss: 2.392 - true_out: 0.860 - fake_out: 0.195>>0.117\n",
      "(1101/1200) ds_loss: 0.397 - gn_loss: 2.431 - true_out: 0.793 - fake_out: 0.124>>0.129\n",
      "Epoch 3/10\n",
      "(1/1200) ds_loss: 0.447 - gn_loss: 3.966 - true_out: 0.954 - fake_out: 0.281>>0.029\n",
      "(101/1200) ds_loss: 0.402 - gn_loss: 2.832 - true_out: 0.874 - fake_out: 0.208>>0.077\n",
      "(201/1200) ds_loss: 0.927 - gn_loss: 3.952 - true_out: 0.960 - fake_out: 0.518>>0.027\n",
      "(301/1200) ds_loss: 0.668 - gn_loss: 3.062 - true_out: 0.869 - fake_out: 0.352>>0.070\n",
      "(401/1200) ds_loss: 0.602 - gn_loss: 2.114 - true_out: 0.660 - fake_out: 0.108>>0.162\n",
      "(501/1200) ds_loss: 0.859 - gn_loss: 4.763 - true_out: 0.970 - fake_out: 0.503>>0.013\n",
      "(601/1200) ds_loss: 0.565 - gn_loss: 2.215 - true_out: 0.751 - fake_out: 0.184>>0.160\n",
      "(701/1200) ds_loss: 0.295 - gn_loss: 3.128 - true_out: 0.940 - fake_out: 0.183>>0.059\n",
      "(801/1200) ds_loss: 0.328 - gn_loss: 3.538 - true_out: 0.929 - fake_out: 0.196>>0.042\n",
      "(901/1200) ds_loss: 0.364 - gn_loss: 2.625 - true_out: 0.743 - fake_out: 0.043>>0.103\n",
      "(1001/1200) ds_loss: 1.077 - gn_loss: 3.144 - true_out: 0.954 - fake_out: 0.566>>0.066\n",
      "(1101/1200) ds_loss: 0.786 - gn_loss: 1.098 - true_out: 0.556 - fake_out: 0.089>>0.417\n",
      "Epoch 4/10\n",
      "(1/1200) ds_loss: 0.744 - gn_loss: 3.602 - true_out: 0.952 - fake_out: 0.422>>0.041\n",
      "(101/1200) ds_loss: 0.418 - gn_loss: 2.434 - true_out: 0.720 - fake_out: 0.047>>0.130\n",
      "(201/1200) ds_loss: 1.000 - gn_loss: 1.724 - true_out: 0.498 - fake_out: 0.102>>0.224\n",
      "(301/1200) ds_loss: 0.979 - gn_loss: 2.603 - true_out: 0.892 - fake_out: 0.513>>0.096\n",
      "(401/1200) ds_loss: 0.316 - gn_loss: 2.706 - true_out: 0.887 - fake_out: 0.151>>0.092\n",
      "(501/1200) ds_loss: 0.760 - gn_loss: 1.739 - true_out: 0.615 - fake_out: 0.163>>0.244\n",
      "(601/1200) ds_loss: 0.355 - gn_loss: 2.729 - true_out: 0.840 - fake_out: 0.137>>0.087\n",
      "(701/1200) ds_loss: 0.527 - gn_loss: 4.041 - true_out: 0.950 - fake_out: 0.326>>0.032\n",
      "(801/1200) ds_loss: 0.345 - gn_loss: 3.530 - true_out: 0.952 - fake_out: 0.230>>0.039\n",
      "(901/1200) ds_loss: 0.407 - gn_loss: 1.905 - true_out: 0.751 - fake_out: 0.068>>0.199\n",
      "(1001/1200) ds_loss: 0.652 - gn_loss: 1.727 - true_out: 0.700 - fake_out: 0.170>>0.224\n",
      "(1101/1200) ds_loss: 0.518 - gn_loss: 3.691 - true_out: 0.884 - fake_out: 0.267>>0.041\n",
      "Epoch 5/10\n",
      "(1/1200) ds_loss: 0.368 - gn_loss: 2.623 - true_out: 0.769 - fake_out: 0.063>>0.112\n",
      "(101/1200) ds_loss: 0.546 - gn_loss: 2.508 - true_out: 0.839 - fake_out: 0.250>>0.121\n",
      "(201/1200) ds_loss: 1.165 - gn_loss: 3.424 - true_out: 0.978 - fake_out: 0.556>>0.062\n",
      "(301/1200) ds_loss: 0.367 - gn_loss: 3.264 - true_out: 0.941 - fake_out: 0.222>>0.056\n",
      "(401/1200) ds_loss: 0.286 - gn_loss: 2.649 - true_out: 0.893 - fake_out: 0.140>>0.086\n",
      "(501/1200) ds_loss: 0.728 - gn_loss: 1.813 - true_out: 0.572 - fake_out: 0.060>>0.228\n",
      "(601/1200) ds_loss: 0.481 - gn_loss: 4.271 - true_out: 0.949 - fake_out: 0.311>>0.018\n",
      "(701/1200) ds_loss: 0.579 - gn_loss: 3.862 - true_out: 0.859 - fake_out: 0.282>>0.031\n",
      "(801/1200) ds_loss: 0.499 - gn_loss: 3.194 - true_out: 0.687 - fake_out: 0.054>>0.083\n",
      "(901/1200) ds_loss: 0.509 - gn_loss: 3.124 - true_out: 0.932 - fake_out: 0.297>>0.061\n",
      "(1001/1200) ds_loss: 0.465 - gn_loss: 2.238 - true_out: 0.849 - fake_out: 0.228>>0.137\n",
      "(1101/1200) ds_loss: 0.212 - gn_loss: 3.106 - true_out: 0.861 - fake_out: 0.049>>0.072\n",
      "Epoch 6/10\n",
      "(1/1200) ds_loss: 0.484 - gn_loss: 3.509 - true_out: 0.916 - fake_out: 0.265>>0.048\n",
      "(101/1200) ds_loss: 0.156 - gn_loss: 4.335 - true_out: 0.960 - fake_out: 0.091>>0.022\n",
      "(201/1200) ds_loss: 0.459 - gn_loss: 4.085 - true_out: 0.906 - fake_out: 0.266>>0.025\n",
      "(301/1200) ds_loss: 0.317 - gn_loss: 3.079 - true_out: 0.832 - fake_out: 0.093>>0.076\n",
      "(401/1200) ds_loss: 0.317 - gn_loss: 3.186 - true_out: 0.910 - fake_out: 0.160>>0.067\n",
      "(501/1200) ds_loss: 0.531 - gn_loss: 3.197 - true_out: 0.653 - fake_out: 0.017>>0.077\n",
      "(601/1200) ds_loss: 0.611 - gn_loss: 3.298 - true_out: 0.941 - fake_out: 0.374>>0.050\n",
      "(701/1200) ds_loss: 0.946 - gn_loss: 4.656 - true_out: 0.991 - fake_out: 0.515>>0.026\n",
      "(801/1200) ds_loss: 0.281 - gn_loss: 2.589 - true_out: 0.842 - fake_out: 0.090>>0.106\n",
      "(901/1200) ds_loss: 0.723 - gn_loss: 1.433 - true_out: 0.575 - fake_out: 0.068>>0.321\n",
      "(1001/1200) ds_loss: 0.268 - gn_loss: 3.094 - true_out: 0.889 - fake_out: 0.119>>0.067\n",
      "(1101/1200) ds_loss: 0.511 - gn_loss: 3.947 - true_out: 0.987 - fake_out: 0.331>>0.032\n",
      "Epoch 7/10\n",
      "(1/1200) ds_loss: 0.272 - gn_loss: 3.483 - true_out: 0.882 - fake_out: 0.112>>0.051\n",
      "(101/1200) ds_loss: 0.437 - gn_loss: 4.443 - true_out: 0.939 - fake_out: 0.276>>0.018\n",
      "(201/1200) ds_loss: 0.323 - gn_loss: 3.814 - true_out: 0.944 - fake_out: 0.213>>0.028\n",
      "(301/1200) ds_loss: 0.800 - gn_loss: 1.304 - true_out: 0.525 - fake_out: 0.019>>0.349\n",
      "(401/1200) ds_loss: 0.620 - gn_loss: 2.428 - true_out: 0.603 - fake_out: 0.003>>0.141\n",
      "(501/1200) ds_loss: 0.278 - gn_loss: 2.969 - true_out: 0.880 - fake_out: 0.116>>0.082\n",
      "(601/1200) ds_loss: 0.315 - gn_loss: 2.887 - true_out: 0.904 - fake_out: 0.170>>0.078\n",
      "(701/1200) ds_loss: 1.028 - gn_loss: 2.310 - true_out: 0.451 - fake_out: 0.011>>0.172\n",
      "(801/1200) ds_loss: 0.235 - gn_loss: 2.507 - true_out: 0.947 - fake_out: 0.145>>0.121\n",
      "(901/1200) ds_loss: 0.597 - gn_loss: 1.678 - true_out: 0.688 - fake_out: 0.105>>0.239\n",
      "(1001/1200) ds_loss: 0.208 - gn_loss: 4.280 - true_out: 0.910 - fake_out: 0.091>>0.021\n",
      "(1101/1200) ds_loss: 0.305 - gn_loss: 3.445 - true_out: 0.904 - fake_out: 0.159>>0.045\n",
      "Epoch 8/10\n",
      "(1/1200) ds_loss: 0.219 - gn_loss: 3.333 - true_out: 0.934 - fake_out: 0.116>>0.048\n",
      "(101/1200) ds_loss: 0.209 - gn_loss: 3.097 - true_out: 0.899 - fake_out: 0.079>>0.066\n",
      "(201/1200) ds_loss: 0.197 - gn_loss: 3.884 - true_out: 0.952 - fake_out: 0.122>>0.029\n",
      "(301/1200) ds_loss: 0.379 - gn_loss: 2.672 - true_out: 0.846 - fake_out: 0.154>>0.099\n",
      "(401/1200) ds_loss: 0.622 - gn_loss: 5.302 - true_out: 0.886 - fake_out: 0.330>>0.008\n",
      "(501/1200) ds_loss: 0.439 - gn_loss: 1.354 - true_out: 0.695 - fake_out: 0.027>>0.328\n",
      "(601/1200) ds_loss: 0.305 - gn_loss: 3.914 - true_out: 0.987 - fake_out: 0.215>>0.029\n",
      "(701/1200) ds_loss: 0.866 - gn_loss: 6.513 - true_out: 0.974 - fake_out: 0.494>>0.002\n",
      "(801/1200) ds_loss: 0.478 - gn_loss: 2.412 - true_out: 0.807 - fake_out: 0.155>>0.146\n",
      "(901/1200) ds_loss: 0.318 - gn_loss: 2.649 - true_out: 0.840 - fake_out: 0.115>>0.110\n",
      "(1001/1200) ds_loss: 0.361 - gn_loss: 3.091 - true_out: 0.742 - fake_out: 0.022>>0.076\n",
      "(1101/1200) ds_loss: 0.155 - gn_loss: 4.252 - true_out: 0.919 - fake_out: 0.058>>0.029\n",
      "Epoch 9/10\n",
      "(1/1200) ds_loss: 0.459 - gn_loss: 3.503 - true_out: 0.921 - fake_out: 0.275>>0.040\n",
      "(101/1200) ds_loss: 0.734 - gn_loss: 5.349 - true_out: 0.982 - fake_out: 0.442>>0.007\n",
      "(201/1200) ds_loss: 0.449 - gn_loss: 3.996 - true_out: 0.949 - fake_out: 0.292>>0.026\n",
      "(301/1200) ds_loss: 0.292 - gn_loss: 4.224 - true_out: 0.970 - fake_out: 0.216>>0.020\n",
      "(401/1200) ds_loss: 0.658 - gn_loss: 5.584 - true_out: 0.932 - fake_out: 0.370>>0.006\n",
      "(501/1200) ds_loss: 0.516 - gn_loss: 3.890 - true_out: 0.864 - fake_out: 0.253>>0.032\n",
      "(601/1200) ds_loss: 0.342 - gn_loss: 2.820 - true_out: 0.883 - fake_out: 0.158>>0.085\n",
      "(701/1200) ds_loss: 0.431 - gn_loss: 3.895 - true_out: 0.965 - fake_out: 0.268>>0.029\n",
      "(801/1200) ds_loss: 0.139 - gn_loss: 3.739 - true_out: 0.919 - fake_out: 0.045>>0.044\n",
      "(901/1200) ds_loss: 0.178 - gn_loss: 3.750 - true_out: 0.881 - fake_out: 0.041>>0.037\n",
      "(1001/1200) ds_loss: 0.399 - gn_loss: 1.897 - true_out: 0.768 - fake_out: 0.088>>0.216\n",
      "(1101/1200) ds_loss: 0.351 - gn_loss: 4.300 - true_out: 0.910 - fake_out: 0.194>>0.022\n",
      "Epoch 10/10\n",
      "(1/1200) ds_loss: 0.522 - gn_loss: 2.278 - true_out: 0.767 - fake_out: 0.150>>0.160\n",
      "(101/1200) ds_loss: 0.178 - gn_loss: 4.337 - true_out: 0.879 - fake_out: 0.031>>0.023\n",
      "(201/1200) ds_loss: 0.164 - gn_loss: 4.825 - true_out: 0.949 - fake_out: 0.097>>0.013\n",
      "(301/1200) ds_loss: 0.172 - gn_loss: 2.786 - true_out: 0.923 - fake_out: 0.077>>0.082\n",
      "(401/1200) ds_loss: 0.176 - gn_loss: 3.659 - true_out: 0.984 - fake_out: 0.139>>0.036\n",
      "(501/1200) ds_loss: 0.172 - gn_loss: 4.159 - true_out: 0.961 - fake_out: 0.107>>0.024\n",
      "(601/1200) ds_loss: 0.064 - gn_loss: 3.949 - true_out: 0.970 - fake_out: 0.030>>0.031\n",
      "(701/1200) ds_loss: 0.587 - gn_loss: 2.811 - true_out: 0.919 - fake_out: 0.318>>0.109\n",
      "(801/1200) ds_loss: 0.593 - gn_loss: 3.234 - true_out: 0.817 - fake_out: 0.246>>0.059\n",
      "(901/1200) ds_loss: 0.341 - gn_loss: 3.951 - true_out: 0.932 - fake_out: 0.206>>0.027\n",
      "(1001/1200) ds_loss: 0.197 - gn_loss: 3.412 - true_out: 0.917 - fake_out: 0.092>>0.049\n",
      "(1101/1200) ds_loss: 0.198 - gn_loss: 4.902 - true_out: 0.902 - fake_out: 0.073>>0.012\n",
      "CPU times: user 7min 12s, sys: 1.79 s, total: 7min 14s\n",
      "Wall time: 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "9. 学習を行う\n",
    "'''\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# 学習回数\n",
    "n_epoch = 10\n",
    "\n",
    "# 画像の保存先のパス\n",
    "# パスは環境に合わせて書き換えることが必要\n",
    "# outf = '/content/drive/MyDrive/Colab Notebooks/GAN/DCGAN_PyTorch/result'\n",
    "outf = \"result\"\n",
    "\n",
    "# エポックごとに出力する生成画像のためのノイズを生成\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size, gn_input_dim, 1, 1, device=device)  \n",
    "\n",
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, n_epoch))\n",
    "\n",
    "    # バッチデータのループ(ステップ)\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        # ミニバッチのすべての画像を取得\n",
    "        real_image = data[0].to(device)\n",
    "        # 画像の枚数を取得(バッチサイズ)\n",
    "        sample_size = real_image.size(0)\n",
    "        \n",
    "        # 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "        noise = torch.randn(sample_size, # バッチサイズ\n",
    "                            gn_input_dim,# 生成器の入力次元100\n",
    "                            1,           # 1\n",
    "                            1,           # 1\n",
    "                            device=device)\n",
    "        # オリジナル画像に対する識別信号の正解値「1」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        real_target = torch.full((sample_size,),\n",
    "                                 1.,\n",
    "                                 device=device)\n",
    "        # 生成画像に対する識別信号の正解値「0」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        fake_target = torch.full((sample_size,),\n",
    "                                 0.,\n",
    "                                 device=device) \n",
    "        \n",
    "        # -----識別器の学習-----\n",
    "        # 識別器の誤差の勾配を初期化\n",
    "        discriminator.zero_grad()    \n",
    "\n",
    "        # 識別器に画像を入力して識別信号を出力\n",
    "        output = discriminator(real_image)\n",
    "        # オリジナル画像に対する識別値の損失を取得\n",
    "        ds_real_err = criterion(output,    # オリジナル画像の識別信号\n",
    "                              real_target) # 正解ラベル(1)\n",
    "        # 1ステップ(1バッチ)におけるオリジナル画像の識別信号の平均\n",
    "        true_dsout_mean = output.mean().item()\n",
    "\n",
    "        # ノイズを生成器に入力してフェイク画像を生成\n",
    "        fake_image = generator(noise)\n",
    "        # フェイク画像を識別器に入力して識別信号を出力\n",
    "        output = discriminator(fake_image.detach())\n",
    "        # フェイク画像を偽と判定できない場合の損失\n",
    "        ds_fake_err = criterion(output,    # フェイク画像の識別信号\n",
    "                              fake_target) # 正解ラベル(偽物の0)\n",
    "        # フェイク画像の識別信号の平均\n",
    "        fake_dsout_mean1 = output.mean().item()\n",
    "        # オリジナル画像とフェイク画像に対する識別の損失を合計して\n",
    "        # 識別器としての損失を求める\n",
    "        ds_err = ds_real_err + ds_fake_err\n",
    "\n",
    "        # 識別器全体の誤差を逆伝播\n",
    "        ds_err.backward()\n",
    "        # 判別器の重みのみを更新(生成器は更新しない)\n",
    "        optimizer_ds.step()\n",
    "\n",
    "        # -----生成器の学習-----\n",
    "        # 生成器の誤差の勾配を初期化\n",
    "        generator.zero_grad()\n",
    "        # 更新した識別器に再度フェイク画像を入力して識別信号を取得\n",
    "        output = discriminator(fake_image)\n",
    "        # フェイク画像をオリジナル画像と誤認できない場合の損失\n",
    "        gn_err = criterion(output,      # フェイク画像の識別信号\n",
    "                           real_target) # 誤認させるのが目的なので正解ラベルは1\n",
    "        # 更新後の識別器の誤差を逆伝播\n",
    "        gn_err.backward() \n",
    "        # 更新後の識別器のフェイク画像に対する識別信号の平均\n",
    "        fake_dsout_mean2 = output.mean().item()\n",
    "        # 生成器の重みを更新後の識別誤差の勾配で更新\n",
    "        optimizer_gn.step()\n",
    "\n",
    "        # 100ステップごとに結果を出力\n",
    "        if itr % 100 == 0: \n",
    "            print(\n",
    "'({}/{}) ds_loss: {:.3f} - gn_loss: {:.3f} - true_out: {:.3f} - fake_out: {:.3f}>>{:.3f}'\n",
    "                  .format(\n",
    "                      itr + 1,          # ステップ数(イテレート回数)\n",
    "                      len(dataloader),  # ステップ数(1エポックのバッチ数)\n",
    "                      ds_err.item(),    # 識別器の損失\n",
    "                      gn_err.item(),    # フェイクをオリジナルと誤認しない損失\n",
    "                      true_dsout_mean,  # オリジナル画像の識別信号の平均\n",
    "                      fake_dsout_mean1, # フェイク画像の識別信号の平均\n",
    "                      fake_dsout_mean2) # 更新後識別器のフェイクの識別信号平均\n",
    "                  )\n",
    "\n",
    "        # 学習開始直後にオリジナル画像を保存する\n",
    "        if epoch == 0 and itr == 0:\n",
    "            vutils.save_image(real_image,\n",
    "                              '{}/real_samples.png'.format(outf),\n",
    "                              normalize=True,\n",
    "                              nrow=10)\n",
    "\n",
    "    # 1エポック終了ごとに生成器が生成した画像を保存\n",
    "    # バッチサイズと同じ数のノイズを生成器に入力\n",
    "    fake_image = generator(fixed_noise)\n",
    "    # 画像を保存\n",
    "    vutils.save_image(\n",
    "        fake_image.detach(),\n",
    "        '{}/generated_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "        normalize=True,\n",
    "        nrow=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN4Xrtqp9hBtIX50A8Kbh3H",
   "collapsed_sections": [],
   "mount_file_id": "1ECSIbSBGrIDcJC5Ky1h5ow1B60M_y5hm",
   "name": "DCGAN_MNIST_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
