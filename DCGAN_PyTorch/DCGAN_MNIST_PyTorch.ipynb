{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7004,
     "status": "ok",
     "timestamp": 1627794892134,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "_5nZnnI0zqJX",
    "outputId": "ebdcf056-eef7-4a1d-e3e4-7e5b60744f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. データセットとデータローダーを用意\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# MNISTデータセットの訓練データを用意\n",
    "dataset = datasets.MNIST(\n",
    "    # mnistフォルダーに保存\n",
    "    # パスは環境に合わせて書き換えることが必要\n",
    "    # root='/content/drive/MyDrive/Colab Notebooks/GAN/DCGAN_PyTorch/mnist',\n",
    "    root=\"mnist\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    # トランスフォームオブジェクトを設定\n",
    "    transform=transforms.Compose(\n",
    "        # Tensorオブジェクトに変換\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            # データを平均0.5、標準偏差0.5の標準正規分布で正規化\n",
    "            # チャネル数は1なのでタプルの要素も1\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size = 50\n",
    "\n",
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,  # ミニバッチのサイズは50\n",
    "    shuffle=True,  # データをシャッフルしてから抽出\n",
    ")\n",
    "\n",
    "# 使用可能なデバイスを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0Th2mvrs1Qc5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. 識別器のクラスを定義 \n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"識別器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"識別器のネットワークを構築する\"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        in_ch = 1  # 入力画像のチャネル数\n",
    "        start_ch = 128  # 先頭層の出力チャネル数\n",
    "\n",
    "        # 識別器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                # 第1層: (bs, 1, 28, 28) -> (bs, 128, 14, 14)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        in_ch,  # 入力のチャネル数は1\n",
    "                        start_ch,  # フィルター数は128\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # LeakyReLU関数を適用\n",
    "                    # 論文に従って負の勾配を制御する係数を\n",
    "                    # 0.2(デフォルトは0.01)に設定\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第2層: (bs, 128, 14, 14) -> (bs, 256, 7, 7)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        start_ch,  # 入力のチャネル数は128\n",
    "                        start_ch * 2,  # フィルター数は128×2\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # 出力値を正規化する(チャネル数は128×2)\n",
    "                    nn.BatchNorm2d(start_ch * 2),\n",
    "                    # LeakyReLU関数を適用\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第3層: (bs, 256, 7, 7) -> (bs, 512, 3, 3)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        start_ch * 2,  # 入力のチャネル数は128×2\n",
    "                        start_ch * 4,  # フィルター数は128×4\n",
    "                        3,  # 3×3のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×4)\n",
    "                    nn.BatchNorm2d(start_ch * 4),\n",
    "                    # leaky ReLU関数を適用\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第4層: (bs, 512, 3, 3) -> (bs, 1, 1, 1)\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        start_ch * 4,  # 入力のチャネル数は128×4\n",
    "                        1,  # フィルター数は1\n",
    "                        3,  # 3×3のフィルター\n",
    "                        1,  # ストライドは1\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 最終出力にはシグモイド関数を適用\n",
    "                    nn.Sigmoid(),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          x: 画像データまたは生成画像\n",
    "        \"\"\"\n",
    "        # 識別器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # 出力されたテンソルの形状をフラット(bs,)にする\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oCOCFhI20lmO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. 生成器のクラスを定義\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"生成器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"生成器のネットワークを構築する\"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        input_dim = 100  # 入力データの次元\n",
    "        out_ch = 128  # 最終層のチャネル数\n",
    "        img_ch = 1  # 生成画像のチャネル数\n",
    "\n",
    "        # 生成器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                # 第1層: (bs, 100, 1, 1) -> (bs, 512, 3, 3)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        input_dim,  # 入力のチャネル数は100\n",
    "                        out_ch * 4,  # フィルター数は128×4\n",
    "                        3,  # 3×3のフィルター\n",
    "                        1,  # ストライドは1\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×4)\n",
    "                    nn.BatchNorm2d(out_ch * 4),\n",
    "                    # ReLU関数を適用\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "                # 第2層: (bs, 512, 3, 3) -> (bs, 256, 7, 7)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        out_ch * 4,  # 入力のチャネル数は128×4\n",
    "                        out_ch * 2,  # フィルター数は128×2\n",
    "                        3,  # 3×3のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×2)\n",
    "                    nn.BatchNorm2d(out_ch * 2),\n",
    "                    # ReLU関数を適用\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "                # 第3層: (bs, 256, 7, 7) -> (bs, 128, 14, 14)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        out_ch * 2,  # 入力のチャネル数は128×2\n",
    "                        out_ch,  # フィルター数は128\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # 出力値を正規化する(チャネル数は128)\n",
    "                    nn.BatchNorm2d(out_ch),\n",
    "                    # ReLU関数を適用\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "                # 第4層: (bs, 128, 14, 14) -> (bs, 1, 28, 28)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        out_ch,  # 入力のチャネル数は128\n",
    "                        img_ch,  # フィルター数は1\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # Tanh関数を適用\n",
    "                    nn.Tanh(),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          z: 識別器の出力\n",
    "        \"\"\"\n",
    "        # 生成器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TZFR5dh_0r0W"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. 重みの初期化を行う関数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    DCGANの論文では重みを正規分布からサンプリングした値で初期化している\n",
    "\n",
    "    Parameters:\n",
    "      m: ネットワークのインスタンス\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    # 畳み込み層の重み\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)  # 平均0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0)  # バイアスのみ0で初期化\n",
    "    # バッチ正規化層の重み\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)  # 平均1.0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0)  # バイアスのみ0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12268,
     "status": "ok",
     "timestamp": 1627794904398,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "rIjYwm-W0zeY",
    "outputId": "06a0da9a-460c-4321-9172-a385225a5213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 3, 3]         461,312\n",
      "       BatchNorm2d-2            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-3            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 7, 7]       1,179,904\n",
      "       BatchNorm2d-5            [-1, 256, 7, 7]             512\n",
      "              ReLU-6            [-1, 256, 7, 7]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 14, 14]         524,416\n",
      "       BatchNorm2d-8          [-1, 128, 14, 14]             256\n",
      "              ReLU-9          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-10            [-1, 1, 28, 28]           2,049\n",
      "             Tanh-11            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 2,169,473\n",
      "Trainable params: 2,169,473\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 8.28\n",
      "Estimated Total Size (MB): 9.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. 生成器をインスタンス化して重みを初期化する\n",
    "\"\"\"\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "# 生成器Generator\n",
    "generator = Generator().to(device)\n",
    "# 重みを初期化\n",
    "generator.apply(weights_init)\n",
    "# 生成器のサマリを出力\n",
    "torchsummary.summary(generator, (100, 1, 1))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1627794904399,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "4sSG9vr8044E",
    "outputId": "5a4d918a-f443-4b83-b2d5-fa12268d3462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 14, 14]           2,176\n",
      "         LeakyReLU-2          [-1, 128, 14, 14]               0\n",
      "            Conv2d-3            [-1, 256, 7, 7]         524,544\n",
      "       BatchNorm2d-4            [-1, 256, 7, 7]             512\n",
      "         LeakyReLU-5            [-1, 256, 7, 7]               0\n",
      "            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "         LeakyReLU-8            [-1, 512, 3, 3]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           4,609\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,713,025\n",
      "Trainable params: 1,713,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.78\n",
      "Params size (MB): 6.53\n",
      "Estimated Total Size (MB): 7.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6. 識別器をインスタンス化して重みを初期化する\n",
    "\"\"\"\n",
    "\n",
    "# 識別器Discriminator\n",
    "discriminator = Discriminator().to(device)\n",
    "# 重みの初期化\n",
    "discriminator.apply(weights_init)\n",
    "# 識別器のサマリを出力\n",
    "torchsummary.summary(discriminator, (1, 28, 28))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fxL2WFs_0_cb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "7. 損失関数とオプティマイザーの設定\n",
    "\"\"\"\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数はバイナリクロスエントロピー誤差\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 識別器のオプティマイザ−を設定\n",
    "optimizer_ds = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    # デフォルトの学習率0.001を論文で提案されている\n",
    "    # # 0.0002に変更\n",
    "    lr=0.0002,\n",
    "    # 指数関数的減衰率としてデフォルトの(0.9, 0.999)\n",
    "    # のβ1の値のみ論文で提案されている(0.5, 0.999)に変更\n",
    "    betas=(0.5, 0.999),\n",
    ")\n",
    "\n",
    "# 生成器のオプティマイザーを設定\n",
    "optimizer_gn = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1CdrKteQGHGB"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8. エポックごとの画像生成に使用するノイズのテンソルを作成\n",
    "\"\"\"\n",
    "\n",
    "gn_input_dim = 100  # 生成器に入力するノイズの次元\n",
    "\n",
    "# エポックごとに出力する生成画像のためのノイズを生成\n",
    "# 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size, gn_input_dim, 1, 1, device=device  # バッチサイズ  # ノイズの次元100  # 1  # 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606572,
     "status": "ok",
     "timestamp": 1627795510955,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "JFzFivDX1D_8",
    "outputId": "5e54e43d-b030-4407-a6db-e2dbaab66870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(1/1200) ds_loss: 2.040 - gn_loss: 2.948 - true_out: 0.406 - fake_out: 0.594>>0.065\n",
      "(101/1200) ds_loss: 0.217 - gn_loss: 5.414 - true_out: 0.928 - fake_out: 0.117>>0.006\n",
      "(201/1200) ds_loss: 0.192 - gn_loss: 4.096 - true_out: 0.916 - fake_out: 0.084>>0.029\n",
      "(301/1200) ds_loss: 0.281 - gn_loss: 3.790 - true_out: 0.898 - fake_out: 0.130>>0.034\n",
      "(401/1200) ds_loss: 0.550 - gn_loss: 2.880 - true_out: 0.967 - fake_out: 0.329>>0.087\n",
      "(501/1200) ds_loss: 0.336 - gn_loss: 4.255 - true_out: 0.918 - fake_out: 0.198>>0.020\n",
      "(601/1200) ds_loss: 0.492 - gn_loss: 2.023 - true_out: 0.767 - fake_out: 0.155>>0.177\n",
      "(701/1200) ds_loss: 0.382 - gn_loss: 2.088 - true_out: 0.795 - fake_out: 0.103>>0.149\n",
      "(801/1200) ds_loss: 0.517 - gn_loss: 3.589 - true_out: 0.914 - fake_out: 0.308>>0.034\n",
      "(901/1200) ds_loss: 0.388 - gn_loss: 2.360 - true_out: 0.803 - fake_out: 0.128>>0.127\n",
      "(1001/1200) ds_loss: 0.441 - gn_loss: 2.774 - true_out: 0.787 - fake_out: 0.138>>0.087\n",
      "(1101/1200) ds_loss: 0.471 - gn_loss: 1.995 - true_out: 0.700 - fake_out: 0.064>>0.183\n",
      "Epoch 2/10\n",
      "(1/1200) ds_loss: 0.344 - gn_loss: 2.303 - true_out: 0.831 - fake_out: 0.117>>0.130\n",
      "(101/1200) ds_loss: 0.363 - gn_loss: 2.607 - true_out: 0.940 - fake_out: 0.239>>0.094\n",
      "(201/1200) ds_loss: 0.275 - gn_loss: 2.878 - true_out: 0.897 - fake_out: 0.138>>0.071\n",
      "(301/1200) ds_loss: 0.592 - gn_loss: 3.376 - true_out: 0.940 - fake_out: 0.353>>0.047\n",
      "(401/1200) ds_loss: 1.120 - gn_loss: 1.191 - true_out: 0.453 - fake_out: 0.145>>0.372\n",
      "(501/1200) ds_loss: 0.638 - gn_loss: 2.082 - true_out: 0.745 - fake_out: 0.225>>0.155\n",
      "(601/1200) ds_loss: 0.367 - gn_loss: 2.023 - true_out: 0.791 - fake_out: 0.105>>0.180\n",
      "(701/1200) ds_loss: 0.788 - gn_loss: 1.108 - true_out: 0.565 - fake_out: 0.110>>0.376\n",
      "(801/1200) ds_loss: 0.326 - gn_loss: 3.103 - true_out: 0.890 - fake_out: 0.160>>0.062\n",
      "(901/1200) ds_loss: 0.489 - gn_loss: 2.723 - true_out: 0.690 - fake_out: 0.060>>0.097\n",
      "(1001/1200) ds_loss: 1.179 - gn_loss: 4.235 - true_out: 0.965 - fake_out: 0.584>>0.026\n",
      "(1101/1200) ds_loss: 0.757 - gn_loss: 1.596 - true_out: 0.601 - fake_out: 0.128>>0.292\n",
      "Epoch 3/10\n",
      "(1/1200) ds_loss: 0.604 - gn_loss: 1.506 - true_out: 0.673 - fake_out: 0.144>>0.268\n",
      "(101/1200) ds_loss: 0.806 - gn_loss: 1.927 - true_out: 0.659 - fake_out: 0.234>>0.197\n",
      "(201/1200) ds_loss: 0.648 - gn_loss: 2.419 - true_out: 0.687 - fake_out: 0.148>>0.134\n",
      "(301/1200) ds_loss: 0.584 - gn_loss: 1.710 - true_out: 0.711 - fake_out: 0.147>>0.242\n",
      "(401/1200) ds_loss: 0.603 - gn_loss: 2.550 - true_out: 0.859 - fake_out: 0.313>>0.104\n",
      "(501/1200) ds_loss: 0.458 - gn_loss: 2.078 - true_out: 0.761 - fake_out: 0.123>>0.179\n",
      "(601/1200) ds_loss: 1.068 - gn_loss: 0.616 - true_out: 0.429 - fake_out: 0.024>>0.588\n",
      "(701/1200) ds_loss: 0.958 - gn_loss: 1.877 - true_out: 0.533 - fake_out: 0.147>>0.239\n",
      "(801/1200) ds_loss: 0.534 - gn_loss: 3.793 - true_out: 0.961 - fake_out: 0.349>>0.034\n",
      "(901/1200) ds_loss: 0.441 - gn_loss: 3.974 - true_out: 0.907 - fake_out: 0.242>>0.029\n",
      "(1001/1200) ds_loss: 0.574 - gn_loss: 3.286 - true_out: 0.889 - fake_out: 0.326>>0.046\n",
      "(1101/1200) ds_loss: 0.348 - gn_loss: 3.212 - true_out: 0.869 - fake_out: 0.161>>0.057\n",
      "Epoch 4/10\n",
      "(1/1200) ds_loss: 1.003 - gn_loss: 2.604 - true_out: 0.831 - fake_out: 0.487>>0.105\n",
      "(101/1200) ds_loss: 0.391 - gn_loss: 2.632 - true_out: 0.773 - fake_out: 0.087>>0.104\n",
      "(201/1200) ds_loss: 0.252 - gn_loss: 3.272 - true_out: 0.904 - fake_out: 0.126>>0.056\n",
      "(301/1200) ds_loss: 0.306 - gn_loss: 2.563 - true_out: 0.807 - fake_out: 0.055>>0.104\n",
      "(401/1200) ds_loss: 0.684 - gn_loss: 4.625 - true_out: 0.974 - fake_out: 0.414>>0.014\n",
      "(501/1200) ds_loss: 0.629 - gn_loss: 1.716 - true_out: 0.677 - fake_out: 0.142>>0.235\n",
      "(601/1200) ds_loss: 0.792 - gn_loss: 1.360 - true_out: 0.546 - fake_out: 0.066>>0.311\n",
      "(701/1200) ds_loss: 0.205 - gn_loss: 3.279 - true_out: 0.930 - fake_out: 0.111>>0.063\n",
      "(801/1200) ds_loss: 0.222 - gn_loss: 3.319 - true_out: 0.907 - fake_out: 0.103>>0.052\n",
      "(901/1200) ds_loss: 0.488 - gn_loss: 2.260 - true_out: 0.781 - fake_out: 0.169>>0.138\n",
      "(1001/1200) ds_loss: 1.021 - gn_loss: 1.244 - true_out: 0.483 - fake_out: 0.111>>0.372\n",
      "(1101/1200) ds_loss: 0.275 - gn_loss: 3.398 - true_out: 0.905 - fake_out: 0.147>>0.040\n",
      "Epoch 5/10\n",
      "(1/1200) ds_loss: 0.299 - gn_loss: 2.501 - true_out: 0.894 - fake_out: 0.149>>0.116\n",
      "(101/1200) ds_loss: 0.403 - gn_loss: 4.346 - true_out: 0.933 - fake_out: 0.244>>0.018\n",
      "(201/1200) ds_loss: 0.658 - gn_loss: 2.630 - true_out: 0.818 - fake_out: 0.301>>0.096\n",
      "(301/1200) ds_loss: 0.789 - gn_loss: 2.032 - true_out: 0.536 - fake_out: 0.036>>0.200\n",
      "(401/1200) ds_loss: 0.380 - gn_loss: 2.674 - true_out: 0.909 - fake_out: 0.215>>0.097\n",
      "(501/1200) ds_loss: 0.931 - gn_loss: 4.714 - true_out: 0.977 - fake_out: 0.520>>0.014\n",
      "(601/1200) ds_loss: 0.325 - gn_loss: 3.155 - true_out: 0.794 - fake_out: 0.056>>0.064\n",
      "(701/1200) ds_loss: 0.534 - gn_loss: 1.422 - true_out: 0.663 - fake_out: 0.043>>0.301\n",
      "(801/1200) ds_loss: 0.317 - gn_loss: 2.525 - true_out: 0.821 - fake_out: 0.071>>0.117\n",
      "(901/1200) ds_loss: 0.172 - gn_loss: 4.254 - true_out: 0.895 - fake_out: 0.051>>0.025\n",
      "(1001/1200) ds_loss: 0.727 - gn_loss: 2.165 - true_out: 0.782 - fake_out: 0.316>>0.143\n",
      "(1101/1200) ds_loss: 0.587 - gn_loss: 2.766 - true_out: 0.830 - fake_out: 0.282>>0.082\n",
      "Epoch 6/10\n",
      "(1/1200) ds_loss: 0.299 - gn_loss: 2.318 - true_out: 0.816 - fake_out: 0.071>>0.137\n",
      "(101/1200) ds_loss: 0.333 - gn_loss: 4.186 - true_out: 0.943 - fake_out: 0.221>>0.022\n",
      "(201/1200) ds_loss: 0.706 - gn_loss: 1.513 - true_out: 0.591 - fake_out: 0.085>>0.280\n",
      "(301/1200) ds_loss: 0.532 - gn_loss: 2.128 - true_out: 0.699 - fake_out: 0.081>>0.177\n",
      "(401/1200) ds_loss: 0.299 - gn_loss: 3.152 - true_out: 0.822 - fake_out: 0.066>>0.072\n",
      "(501/1200) ds_loss: 0.316 - gn_loss: 2.850 - true_out: 0.785 - fake_out: 0.039>>0.095\n",
      "(601/1200) ds_loss: 0.460 - gn_loss: 3.755 - true_out: 0.915 - fake_out: 0.272>>0.033\n",
      "(701/1200) ds_loss: 0.332 - gn_loss: 3.262 - true_out: 0.884 - fake_out: 0.168>>0.055\n",
      "(801/1200) ds_loss: 0.275 - gn_loss: 2.700 - true_out: 0.883 - fake_out: 0.126>>0.089\n",
      "(901/1200) ds_loss: 0.332 - gn_loss: 2.609 - true_out: 0.848 - fake_out: 0.122>>0.111\n",
      "(1001/1200) ds_loss: 0.668 - gn_loss: 5.424 - true_out: 0.961 - fake_out: 0.391>>0.008\n",
      "(1101/1200) ds_loss: 0.269 - gn_loss: 2.861 - true_out: 0.814 - fake_out: 0.033>>0.091\n",
      "Epoch 7/10\n",
      "(1/1200) ds_loss: 0.522 - gn_loss: 2.884 - true_out: 0.928 - fake_out: 0.310>>0.083\n",
      "(101/1200) ds_loss: 0.290 - gn_loss: 3.284 - true_out: 0.905 - fake_out: 0.156>>0.048\n",
      "(201/1200) ds_loss: 0.367 - gn_loss: 2.121 - true_out: 0.888 - fake_out: 0.190>>0.162\n",
      "(301/1200) ds_loss: 0.649 - gn_loss: 3.789 - true_out: 0.978 - fake_out: 0.398>>0.037\n",
      "(401/1200) ds_loss: 0.391 - gn_loss: 4.059 - true_out: 0.774 - fake_out: 0.051>>0.034\n",
      "(501/1200) ds_loss: 0.732 - gn_loss: 3.603 - true_out: 0.815 - fake_out: 0.317>>0.039\n",
      "(601/1200) ds_loss: 0.342 - gn_loss: 1.862 - true_out: 0.846 - fake_out: 0.120>>0.187\n",
      "(701/1200) ds_loss: 0.524 - gn_loss: 4.579 - true_out: 0.982 - fake_out: 0.335>>0.017\n",
      "(801/1200) ds_loss: 0.288 - gn_loss: 4.832 - true_out: 0.972 - fake_out: 0.205>>0.011\n",
      "(901/1200) ds_loss: 0.423 - gn_loss: 1.532 - true_out: 0.723 - fake_out: 0.051>>0.273\n",
      "(1001/1200) ds_loss: 0.525 - gn_loss: 3.830 - true_out: 0.944 - fake_out: 0.313>>0.040\n",
      "(1101/1200) ds_loss: 0.945 - gn_loss: 0.654 - true_out: 0.475 - fake_out: 0.069>>0.576\n",
      "Epoch 8/10\n",
      "(1/1200) ds_loss: 0.428 - gn_loss: 2.438 - true_out: 0.688 - fake_out: 0.022>>0.119\n",
      "(101/1200) ds_loss: 0.287 - gn_loss: 2.770 - true_out: 0.899 - fake_out: 0.141>>0.098\n",
      "(201/1200) ds_loss: 0.501 - gn_loss: 2.262 - true_out: 0.805 - fake_out: 0.192>>0.153\n",
      "(301/1200) ds_loss: 0.175 - gn_loss: 4.228 - true_out: 0.902 - fake_out: 0.055>>0.029\n",
      "(401/1200) ds_loss: 0.236 - gn_loss: 3.565 - true_out: 0.887 - fake_out: 0.086>>0.053\n",
      "(501/1200) ds_loss: 0.430 - gn_loss: 4.759 - true_out: 0.949 - fake_out: 0.273>>0.012\n",
      "(601/1200) ds_loss: 0.293 - gn_loss: 3.248 - true_out: 0.812 - fake_out: 0.019>>0.070\n",
      "(701/1200) ds_loss: 0.440 - gn_loss: 2.304 - true_out: 0.802 - fake_out: 0.172>>0.151\n",
      "(801/1200) ds_loss: 0.411 - gn_loss: 1.867 - true_out: 0.752 - fake_out: 0.065>>0.236\n",
      "(901/1200) ds_loss: 0.739 - gn_loss: 4.344 - true_out: 0.782 - fake_out: 0.290>>0.026\n",
      "(1001/1200) ds_loss: 0.487 - gn_loss: 2.282 - true_out: 0.768 - fake_out: 0.147>>0.153\n",
      "(1101/1200) ds_loss: 0.391 - gn_loss: 3.663 - true_out: 0.721 - fake_out: 0.028>>0.045\n",
      "Epoch 9/10\n",
      "(1/1200) ds_loss: 0.382 - gn_loss: 4.195 - true_out: 0.734 - fake_out: 0.022>>0.034\n",
      "(101/1200) ds_loss: 0.447 - gn_loss: 2.393 - true_out: 0.708 - fake_out: 0.044>>0.145\n",
      "(201/1200) ds_loss: 0.299 - gn_loss: 2.973 - true_out: 0.905 - fake_out: 0.145>>0.070\n",
      "(301/1200) ds_loss: 0.844 - gn_loss: 4.743 - true_out: 0.981 - fake_out: 0.457>>0.013\n",
      "(401/1200) ds_loss: 0.236 - gn_loss: 2.512 - true_out: 0.864 - fake_out: 0.064>>0.121\n",
      "(501/1200) ds_loss: 0.302 - gn_loss: 2.867 - true_out: 0.777 - fake_out: 0.025>>0.097\n",
      "(601/1200) ds_loss: 0.399 - gn_loss: 3.932 - true_out: 0.856 - fake_out: 0.154>>0.029\n",
      "(701/1200) ds_loss: 0.254 - gn_loss: 3.862 - true_out: 0.936 - fake_out: 0.153>>0.031\n",
      "(801/1200) ds_loss: 0.122 - gn_loss: 3.260 - true_out: 0.945 - fake_out: 0.056>>0.058\n",
      "(901/1200) ds_loss: 0.891 - gn_loss: 2.117 - true_out: 0.499 - fake_out: 0.019>>0.195\n",
      "(1001/1200) ds_loss: 0.233 - gn_loss: 3.836 - true_out: 0.867 - fake_out: 0.070>>0.035\n",
      "(1101/1200) ds_loss: 0.339 - gn_loss: 2.209 - true_out: 0.811 - fake_out: 0.094>>0.141\n",
      "Epoch 10/10\n",
      "(1/1200) ds_loss: 0.215 - gn_loss: 2.467 - true_out: 0.882 - fake_out: 0.074>>0.119\n",
      "(101/1200) ds_loss: 0.343 - gn_loss: 3.199 - true_out: 0.851 - fake_out: 0.124>>0.065\n",
      "(201/1200) ds_loss: 0.223 - gn_loss: 4.127 - true_out: 0.832 - fake_out: 0.023>>0.028\n",
      "(301/1200) ds_loss: 0.879 - gn_loss: 4.464 - true_out: 0.931 - fake_out: 0.479>>0.016\n",
      "(401/1200) ds_loss: 0.735 - gn_loss: 1.666 - true_out: 0.578 - fake_out: 0.046>>0.246\n",
      "(501/1200) ds_loss: 0.232 - gn_loss: 3.032 - true_out: 0.935 - fake_out: 0.123>>0.071\n",
      "(601/1200) ds_loss: 0.093 - gn_loss: 3.704 - true_out: 0.941 - fake_out: 0.030>>0.043\n",
      "(701/1200) ds_loss: 0.206 - gn_loss: 3.136 - true_out: 0.887 - fake_out: 0.074>>0.072\n",
      "(801/1200) ds_loss: 0.454 - gn_loss: 2.618 - true_out: 0.881 - fake_out: 0.223>>0.099\n",
      "(901/1200) ds_loss: 0.251 - gn_loss: 4.158 - true_out: 0.932 - fake_out: 0.150>>0.024\n",
      "(1001/1200) ds_loss: 0.304 - gn_loss: 4.165 - true_out: 0.978 - fake_out: 0.218>>0.022\n",
      "(1101/1200) ds_loss: 0.314 - gn_loss: 3.233 - true_out: 0.944 - fake_out: 0.210>>0.053\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "9. 学習を行う\n",
    "\"\"\"\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# 学習回数\n",
    "n_epoch = 10\n",
    "\n",
    "# 画像の保存先のパス\n",
    "# パスは環境に合わせて書き換えることが必要\n",
    "# outf = '/content/drive/MyDrive/Colab Notebooks/GAN/DCGAN_PyTorch/result'\n",
    "# outf = \"result\"\n",
    "outf = \"/home/a6000/github/pilot-GAN/DCGAN_PyTorch/result\"\n",
    "\n",
    "# エポックごとに出力する生成画像のためのノイズを生成\n",
    "fixed_noise = torch.randn(batch_size, gn_input_dim, 1, 1, device=device)\n",
    "\n",
    "# save initial image (should be random?)\n",
    "fake_image = generator(fixed_noise)\n",
    "# 画像を保存\n",
    "vutils.save_image(\n",
    "    fake_image.detach(),\n",
    "    \"{}/generated_epoch_{:03d}.png\".format(outf, 0),\n",
    "    normalize=True,\n",
    "    nrow=10,\n",
    ")\n",
    "\n",
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, n_epoch))\n",
    "\n",
    "    # バッチデータのループ(ステップ)\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        # ミニバッチのすべての画像を取得\n",
    "        real_image = data[0].to(device)\n",
    "        # 画像の枚数を取得(バッチサイズ)\n",
    "        sample_size = real_image.size(0)\n",
    "\n",
    "        # 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "        noise = torch.randn(\n",
    "            sample_size,  # バッチサイズ\n",
    "            gn_input_dim,  # 生成器の入力次元100\n",
    "            1,  # 1\n",
    "            1,  # 1\n",
    "            device=device,\n",
    "        )\n",
    "        # オリジナル画像に対する識別信号の正解値「1」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        real_target = torch.full((sample_size,), 1.0, device=device)\n",
    "        # 生成画像に対する識別信号の正解値「0」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        fake_target = torch.full((sample_size,), 0.0, device=device)\n",
    "\n",
    "        # -----識別器の学習-----\n",
    "        # 識別器の誤差の勾配を初期化\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # 識別器に画像を入力して識別信号を出力\n",
    "        output = discriminator(real_image)\n",
    "        # オリジナル画像に対する識別値の損失を取得\n",
    "        ds_real_err = criterion(output, real_target)  # オリジナル画像の識別信号  # 正解ラベル(1)\n",
    "        # 1ステップ(1バッチ)におけるオリジナル画像の識別信号の平均\n",
    "        true_dsout_mean = output.mean().item()\n",
    "\n",
    "        # ノイズを生成器に入力してフェイク画像を生成\n",
    "        fake_image = generator(noise)\n",
    "        # フェイク画像を識別器に入力して識別信号を出力\n",
    "        output = discriminator(fake_image.detach())\n",
    "        # フェイク画像を偽と判定できない場合の損失\n",
    "        ds_fake_err = criterion(\n",
    "            output, fake_target  # フェイク画像の識別信号\n",
    "        )  # 正解ラベル(偽物の0)\n",
    "        # フェイク画像の識別信号の平均\n",
    "        fake_dsout_mean1 = output.mean().item()\n",
    "        # オリジナル画像とフェイク画像に対する識別の損失を合計して\n",
    "        # 識別器としての損失を求める\n",
    "        ds_err = ds_real_err + ds_fake_err\n",
    "\n",
    "        # 識別器全体の誤差を逆伝播\n",
    "        ds_err.backward()\n",
    "        # 判別器の重みのみを更新(生成器は更新しない)\n",
    "        optimizer_ds.step()\n",
    "\n",
    "        # -----生成器の学習-----\n",
    "        # 生成器の誤差の勾配を初期化\n",
    "        generator.zero_grad()\n",
    "        # 更新した識別器に再度フェイク画像を入力して識別信号を取得\n",
    "        output = discriminator(fake_image)\n",
    "        # フェイク画像をオリジナル画像と誤認できない場合の損失\n",
    "        gn_err = criterion(\n",
    "            output, real_target  # フェイク画像の識別信号\n",
    "        )  # 誤認させるのが目的なので正解ラベルは1\n",
    "        # 更新後の識別器の誤差を逆伝播\n",
    "        gn_err.backward()\n",
    "        # 更新後の識別器のフェイク画像に対する識別信号の平均\n",
    "        fake_dsout_mean2 = output.mean().item()\n",
    "        # 生成器の重みを更新後の識別誤差の勾配で更新\n",
    "        optimizer_gn.step()\n",
    "\n",
    "        # 100ステップごとに結果を出力\n",
    "        if itr % 100 == 0:\n",
    "            print(\n",
    "                \"({}/{}) ds_loss: {:.3f} - gn_loss: {:.3f} - true_out: {:.3f} - fake_out: {:.3f}>>{:.3f}\".format(\n",
    "                    itr + 1,  # ステップ数(イテレート回数)\n",
    "                    len(dataloader),  # ステップ数(1エポックのバッチ数)\n",
    "                    ds_err.item(),  # 識別器の損失\n",
    "                    gn_err.item(),  # フェイクをオリジナルと誤認しない損失\n",
    "                    true_dsout_mean,  # オリジナル画像の識別信号の平均\n",
    "                    fake_dsout_mean1,  # フェイク画像の識別信号の平均\n",
    "                    fake_dsout_mean2,\n",
    "                )  # 更新後識別器のフェイクの識別信号平均\n",
    "            )\n",
    "\n",
    "        # 学習開始直後にオリジナル画像を保存する\n",
    "        if epoch == 0 and itr == 0:\n",
    "            vutils.save_image(\n",
    "                real_image, \"{}/real_samples.png\".format(outf), normalize=True, nrow=10\n",
    "            )\n",
    "\n",
    "    # 1エポック終了ごとに生成器が生成した画像を保存\n",
    "    # バッチサイズと同じ数のノイズを生成器に入力\n",
    "    fake_image = generator(fixed_noise)\n",
    "    # 画像を保存\n",
    "    vutils.save_image(\n",
    "        fake_image.detach(),\n",
    "        \"{}/generated_epoch_{:03d}.png\".format(outf, epoch + 1),\n",
    "        normalize=True,\n",
    "        nrow=10,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN4Xrtqp9hBtIX50A8Kbh3H",
   "collapsed_sections": [],
   "mount_file_id": "1ECSIbSBGrIDcJC5Ky1h5ow1B60M_y5hm",
   "name": "DCGAN_MNIST_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
