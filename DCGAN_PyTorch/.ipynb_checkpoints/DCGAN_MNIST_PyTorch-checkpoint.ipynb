{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7004,
     "status": "ok",
     "timestamp": 1627794892134,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "_5nZnnI0zqJX",
    "outputId": "ebdcf056-eef7-4a1d-e3e4-7e5b60744f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03adf790bf744818466111756e1988b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de99359df0fa416598f425cd99aa3edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5e41081bd34b8b94920b62e5a95ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a862dbbdfeac451390f7a02bd8931827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. データセットとデータローダーを用意\n",
    "'''\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# MNISTデータセットの訓練データを用意\n",
    "dataset = datasets.MNIST(\n",
    "    # mnistフォルダーに保存\n",
    "    # パスは環境に合わせて書き換えることが必要\n",
    "    # root='/content/drive/MyDrive/Colab Notebooks/GAN/DCGAN_PyTorch/mnist',\n",
    "    root=\"mnist\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    # トランスフォームオブジェクトを設定\n",
    "    transform=transforms.Compose(\n",
    "        # Tensorオブジェクトに変換\n",
    "        [transforms.ToTensor(),\n",
    "         # データを平均0.5、標準偏差0.5の標準正規分布で正規化\n",
    "         # チャネル数は1なのでタプルの要素も1\n",
    "         transforms.Normalize((0.5,), (0.5,))]\n",
    "         )\n",
    "    )\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size=50\n",
    "\n",
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size, # ミニバッチのサイズは50\n",
    "    shuffle=True,          # データをシャッフルしてから抽出\n",
    "    )\n",
    "\n",
    "# 使用可能なデバイスを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Th2mvrs1Qc5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "2. 識別器のクラスを定義 \n",
    "'''\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    '''識別器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''識別器のネットワークを構築する\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        in_ch = 1      # 入力画像のチャネル数\n",
    "        start_ch = 128 # 先頭層の出力チャネル数\n",
    "\n",
    "        # 識別器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList([\n",
    "            # 第1層: (bs, 1, 28, 28) -> (bs, 128, 14, 14)\n",
    "            nn.Sequential(\n",
    "                # 畳み込み\n",
    "                nn.Conv2d(in_ch,    # 入力のチャネル数は1\n",
    "                          start_ch, # フィルター数は128\n",
    "                          4,  # 4×4のフィルター\n",
    "                          2,  # ストライドは2\n",
    "                          1), # 上下左右にサイズ1のパディング\n",
    "                # LeakyReLU関数を適用\n",
    "                # 論文に従って負の勾配を制御する係数を\n",
    "                # 0.2(デフォルトは0.01)に設定\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ), \n",
    "            # 第2層: (bs, 128, 14, 14) -> (bs, 256, 7, 7)\n",
    "            nn.Sequential(\n",
    "                # 畳み込み\n",
    "                nn.Conv2d(start_ch,     # 入力のチャネル数は128\n",
    "                          start_ch * 2, # フィルター数は128×2\n",
    "                          4,  # 4×4のフィルター\n",
    "                          2,  # ストライドは2\n",
    "                          1), # 上下左右にサイズ1のパディング\n",
    "                # 出力値を正規化する(チャネル数は128×2)\n",
    "                nn.BatchNorm2d(start_ch * 2),\n",
    "                # LeakyReLU関数を適用\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ),\n",
    "            # 第3層: (bs, 256, 7, 7) -> (bs, 512, 3, 3)\n",
    "            nn.Sequential(\n",
    "                # 畳み込み\n",
    "                nn.Conv2d(start_ch * 2, # 入力のチャネル数は128×2\n",
    "                          start_ch * 4, # フィルター数は128×4\n",
    "                          3,  # 3×3のフィルター\n",
    "                          2,  # ストライドは2\n",
    "                          0), # パディングは0(なし)\n",
    "                # 出力値を正規化する(チャネル数は128×4)\n",
    "                nn.BatchNorm2d(start_ch * 4),\n",
    "                # leaky ReLU関数を適用\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            ),\n",
    "            # 第4層: (bs, 512, 3, 3) -> (bs, 1, 1, 1)\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(start_ch * 4, # 入力のチャネル数は128×4\n",
    "                          1,  # フィルター数は1\n",
    "                          3,  # 3×3のフィルター\n",
    "                          1,  # ストライドは1\n",
    "                          0), # パディングは0(なし)\n",
    "                # 最終出力にはシグモイド関数を適用\n",
    "                nn.Sigmoid()\n",
    "            )    \n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          x: 画像データまたは生成画像\n",
    "        '''\n",
    "        # 識別器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # 出力されたテンソルの形状をフラット(bs,)にする\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oCOCFhI20lmO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "3. 生成器のクラスを定義\n",
    "'''\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    '''生成器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''生成器のネットワークを構築する\n",
    "        '''\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        input_dim = 100 # 入力データの次元\n",
    "        out_ch = 128    # 最終層のチャネル数\n",
    "        img_ch = 1      # 生成画像のチャネル数\n",
    "\n",
    "        # 生成器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList([\n",
    "            # 第1層: (bs, 100, 1, 1) -> (bs, 512, 3, 3)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_dim,  # 入力のチャネル数は100\n",
    "                                   out_ch * 4, # フィルター数は128×4\n",
    "                                   3,          # 3×3のフィルター\n",
    "                                   1,          # ストライドは1\n",
    "                                   0),         # パディングは0(なし)\n",
    "                # 出力値を正規化する(チャネル数は128×4)\n",
    "                nn.BatchNorm2d(out_ch * 4),\n",
    "                # ReLU関数を適用\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            # 第2層: (bs, 512, 3, 3) -> (bs, 256, 7, 7)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_ch * 4, # 入力のチャネル数は128×4\n",
    "                                   out_ch * 2, # フィルター数は128×2\n",
    "                                   3,          # 3×3のフィルター\n",
    "                                   2,          # ストライドは2\n",
    "                                   0),         # パディングは0(なし)\n",
    "                # 出力値を正規化する(チャネル数は128×2)\n",
    "                nn.BatchNorm2d(out_ch * 2),\n",
    "                # ReLU関数を適用\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            # 第3層: (bs, 256, 7, 7) -> (bs, 128, 14, 14)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_ch * 2, # 入力のチャネル数は128×2\n",
    "                                   out_ch,     # フィルター数は128\n",
    "                                   4,          # 4×4のフィルター\n",
    "                                   2,          # ストライドは2\n",
    "                                   1), # 上下左右にサイズ1のパディング\n",
    "                # 出力値を正規化する(チャネル数は128)\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                # ReLU関数を適用\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            # 第4層: (bs, 128, 14, 14) -> (bs, 1, 28, 28)\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(out_ch, # 入力のチャネル数は128\n",
    "                                   img_ch, # フィルター数は1\n",
    "                                   4,      # 4×4のフィルター\n",
    "                                   2,      # ストライドは2\n",
    "                                   1), # 上下左右にサイズ1のパディング\n",
    "                # Tanh関数を適用\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def forward(self, z):\n",
    "        '''順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          z: 識別器の出力\n",
    "        '''\n",
    "        # 生成器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TZFR5dh_0r0W"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "4. 重みの初期化を行う関数\n",
    "'''\n",
    "def weights_init(m):\n",
    "    '''\n",
    "    DCGANの論文では重みを正規分布からサンプリングした値で初期化している\n",
    "    \n",
    "    Parameters:\n",
    "      m: ネットワークのインスタンス\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    # 畳み込み層の重み\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02) # 平均0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0) # バイアスのみ0で初期化\n",
    "    # バッチ正規化層の重み\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02) # 平均1.0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0) # バイアスのみ0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12268,
     "status": "ok",
     "timestamp": 1627794904398,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "rIjYwm-W0zeY",
    "outputId": "06a0da9a-460c-4321-9172-a385225a5213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 3, 3]         461,312\n",
      "       BatchNorm2d-2            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-3            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 7, 7]       1,179,904\n",
      "       BatchNorm2d-5            [-1, 256, 7, 7]             512\n",
      "              ReLU-6            [-1, 256, 7, 7]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 14, 14]         524,416\n",
      "       BatchNorm2d-8          [-1, 128, 14, 14]             256\n",
      "              ReLU-9          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-10            [-1, 1, 28, 28]           2,049\n",
      "             Tanh-11            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 2,169,473\n",
      "Trainable params: 2,169,473\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 8.28\n",
      "Estimated Total Size (MB): 9.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "5. 生成器をインスタンス化して重みを初期化する\n",
    "'''\n",
    "import torchsummary\n",
    "\n",
    "# 生成器Generator\n",
    "generator = Generator().to(device)\n",
    "# 重みを初期化\n",
    "generator.apply(weights_init)\n",
    "# 生成器のサマリを出力\n",
    "torchsummary.summary(generator,\n",
    "                     (100, 1, 1))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1627794904399,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "4sSG9vr8044E",
    "outputId": "5a4d918a-f443-4b83-b2d5-fa12268d3462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 14, 14]           2,176\n",
      "         LeakyReLU-2          [-1, 128, 14, 14]               0\n",
      "            Conv2d-3            [-1, 256, 7, 7]         524,544\n",
      "       BatchNorm2d-4            [-1, 256, 7, 7]             512\n",
      "         LeakyReLU-5            [-1, 256, 7, 7]               0\n",
      "            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "         LeakyReLU-8            [-1, 512, 3, 3]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           4,609\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,713,025\n",
      "Trainable params: 1,713,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.78\n",
      "Params size (MB): 6.53\n",
      "Estimated Total Size (MB): 7.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "6. 識別器をインスタンス化して重みを初期化する\n",
    "'''\n",
    "# 識別器Discriminator\n",
    "discriminator = Discriminator().to(device)\n",
    "# 重みの初期化\n",
    "discriminator.apply(weights_init)\n",
    "# 識別器のサマリを出力\n",
    "torchsummary.summary(discriminator,\n",
    "                     (1, 28, 28))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fxL2WFs_0_cb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "7. 損失関数とオプティマイザーの設定\n",
    "'''\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数はバイナリクロスエントロピー誤差\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 識別器のオプティマイザ−を設定\n",
    "optimizer_ds = optim.Adam(discriminator.parameters(),\n",
    "                          # デフォルトの学習率0.001を論文で提案されている\n",
    "                          # 0.0002に変更\n",
    "                          lr=0.0002,\n",
    "                          # 指数関数的減衰率としてデフォルトの(0.9, 0.999)\n",
    "                          # のβ1の値のみ論文で提案されている(0.5, 0.999)に変更\n",
    "                          betas=(0.5, 0.999)\n",
    "                          )\n",
    "\n",
    "# 生成器のオプティマイザーを設定\n",
    "optimizer_gn = optim.Adam(generator.parameters(),\n",
    "                          lr=0.0002,\n",
    "                          betas=(0.5, 0.999)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1CdrKteQGHGB"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "8. エポックごとの画像生成に使用するノイズのテンソルを作成\n",
    "'''\n",
    "gn_input_dim = 100  # 生成器に入力するノイズの次元\n",
    "\n",
    "# エポックごとに出力する生成画像のためのノイズを生成\n",
    "# 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size,   # バッチサイズ\n",
    "    gn_input_dim, # ノイズの次元100\n",
    "    1,            # 1\n",
    "    1,            # 1\n",
    "    device=device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 606572,
     "status": "ok",
     "timestamp": 1627795510955,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "JFzFivDX1D_8",
    "outputId": "5e54e43d-b030-4407-a6db-e2dbaab66870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(1/1200) ds_loss: 1.822 - gn_loss: 2.326 - true_out: 0.485 - fake_out: 0.616>>0.114\n",
      "(101/1200) ds_loss: 0.965 - gn_loss: 9.872 - true_out: 0.987 - fake_out: 0.525>>0.000\n",
      "(201/1200) ds_loss: 0.463 - gn_loss: 6.954 - true_out: 0.941 - fake_out: 0.275>>0.002\n",
      "(301/1200) ds_loss: 0.590 - gn_loss: 3.220 - true_out: 0.783 - fake_out: 0.214>>0.066\n",
      "(401/1200) ds_loss: 1.120 - gn_loss: 3.771 - true_out: 0.986 - fake_out: 0.578>>0.041\n",
      "(501/1200) ds_loss: 0.263 - gn_loss: 3.880 - true_out: 0.938 - fake_out: 0.171>>0.028\n",
      "(601/1200) ds_loss: 0.357 - gn_loss: 2.951 - true_out: 0.896 - fake_out: 0.188>>0.072\n",
      "(701/1200) ds_loss: 0.703 - gn_loss: 3.711 - true_out: 0.764 - fake_out: 0.217>>0.048\n",
      "(801/1200) ds_loss: 0.616 - gn_loss: 2.687 - true_out: 0.794 - fake_out: 0.269>>0.086\n",
      "(901/1200) ds_loss: 1.021 - gn_loss: 4.314 - true_out: 0.975 - fake_out: 0.546>>0.023\n",
      "(1001/1200) ds_loss: 0.536 - gn_loss: 1.712 - true_out: 0.641 - fake_out: 0.044>>0.230\n",
      "(1101/1200) ds_loss: 0.478 - gn_loss: 2.751 - true_out: 0.858 - fake_out: 0.247>>0.080\n",
      "Epoch 2/10\n",
      "(1/1200) ds_loss: 0.227 - gn_loss: 2.800 - true_out: 0.901 - fake_out: 0.104>>0.083\n",
      "(101/1200) ds_loss: 0.363 - gn_loss: 1.570 - true_out: 0.807 - fake_out: 0.112>>0.249\n",
      "(201/1200) ds_loss: 0.333 - gn_loss: 2.901 - true_out: 0.901 - fake_out: 0.185>>0.075\n",
      "(301/1200) ds_loss: 0.662 - gn_loss: 2.638 - true_out: 0.811 - fake_out: 0.308>>0.096\n",
      "(401/1200) ds_loss: 0.472 - gn_loss: 2.173 - true_out: 0.855 - fake_out: 0.234>>0.140\n",
      "(501/1200) ds_loss: 0.448 - gn_loss: 1.884 - true_out: 0.748 - fake_out: 0.107>>0.183\n",
      "(601/1200) ds_loss: 0.667 - gn_loss: 1.914 - true_out: 0.695 - fake_out: 0.188>>0.180\n",
      "(701/1200) ds_loss: 0.428 - gn_loss: 2.223 - true_out: 0.866 - fake_out: 0.220>>0.139\n",
      "(801/1200) ds_loss: 0.396 - gn_loss: 3.010 - true_out: 0.922 - fake_out: 0.240>>0.066\n",
      "(901/1200) ds_loss: 0.661 - gn_loss: 3.023 - true_out: 0.866 - fake_out: 0.357>>0.067\n",
      "(1001/1200) ds_loss: 1.332 - gn_loss: 1.399 - true_out: 0.344 - fake_out: 0.013>>0.309\n",
      "(1101/1200) ds_loss: 0.453 - gn_loss: 3.057 - true_out: 0.927 - fake_out: 0.284>>0.065\n",
      "Epoch 3/10\n",
      "(1/1200) ds_loss: 0.881 - gn_loss: 3.917 - true_out: 0.931 - fake_out: 0.489>>0.032\n",
      "(101/1200) ds_loss: 0.759 - gn_loss: 3.581 - true_out: 0.905 - fake_out: 0.423>>0.042\n",
      "(201/1200) ds_loss: 0.863 - gn_loss: 1.629 - true_out: 0.629 - fake_out: 0.244>>0.239\n",
      "(301/1200) ds_loss: 0.771 - gn_loss: 3.906 - true_out: 0.968 - fake_out: 0.448>>0.030\n",
      "(401/1200) ds_loss: 0.403 - gn_loss: 3.498 - true_out: 0.917 - fake_out: 0.245>>0.041\n",
      "(501/1200) ds_loss: 0.943 - gn_loss: 2.512 - true_out: 0.754 - fake_out: 0.402>>0.118\n",
      "(601/1200) ds_loss: 0.494 - gn_loss: 2.410 - true_out: 0.843 - fake_out: 0.242>>0.121\n",
      "(701/1200) ds_loss: 1.573 - gn_loss: 3.923 - true_out: 0.981 - fake_out: 0.714>>0.033\n",
      "(801/1200) ds_loss: 0.214 - gn_loss: 2.987 - true_out: 0.894 - fake_out: 0.085>>0.067\n",
      "(901/1200) ds_loss: 0.468 - gn_loss: 2.416 - true_out: 0.733 - fake_out: 0.087>>0.139\n",
      "(1001/1200) ds_loss: 0.567 - gn_loss: 2.905 - true_out: 0.696 - fake_out: 0.095>>0.099\n",
      "(1101/1200) ds_loss: 0.813 - gn_loss: 2.291 - true_out: 0.767 - fake_out: 0.358>>0.132\n",
      "Epoch 4/10\n",
      "(1/1200) ds_loss: 1.473 - gn_loss: 3.983 - true_out: 0.981 - fake_out: 0.642>>0.051\n",
      "(101/1200) ds_loss: 0.303 - gn_loss: 2.182 - true_out: 0.838 - fake_out: 0.097>>0.148\n",
      "(201/1200) ds_loss: 0.482 - gn_loss: 2.820 - true_out: 0.810 - fake_out: 0.180>>0.086\n",
      "(301/1200) ds_loss: 0.498 - gn_loss: 2.057 - true_out: 0.720 - fake_out: 0.111>>0.173\n",
      "(401/1200) ds_loss: 0.666 - gn_loss: 2.185 - true_out: 0.723 - fake_out: 0.227>>0.171\n",
      "(501/1200) ds_loss: 0.350 - gn_loss: 2.878 - true_out: 0.885 - fake_out: 0.168>>0.085\n",
      "(601/1200) ds_loss: 0.861 - gn_loss: 2.247 - true_out: 0.781 - fake_out: 0.376>>0.141\n",
      "(701/1200) ds_loss: 0.307 - gn_loss: 2.537 - true_out: 0.872 - fake_out: 0.139>>0.112\n",
      "(801/1200) ds_loss: 0.461 - gn_loss: 2.747 - true_out: 0.754 - fake_out: 0.122>>0.103\n",
      "(901/1200) ds_loss: 0.581 - gn_loss: 2.493 - true_out: 0.725 - fake_out: 0.177>>0.114\n",
      "(1001/1200) ds_loss: 0.437 - gn_loss: 2.715 - true_out: 0.856 - fake_out: 0.219>>0.087\n",
      "(1101/1200) ds_loss: 0.551 - gn_loss: 2.114 - true_out: 0.782 - fake_out: 0.203>>0.156\n",
      "Epoch 5/10\n",
      "(1/1200) ds_loss: 0.363 - gn_loss: 2.172 - true_out: 0.788 - fake_out: 0.096>>0.161\n",
      "(101/1200) ds_loss: 0.680 - gn_loss: 4.376 - true_out: 0.876 - fake_out: 0.352>>0.018\n",
      "(201/1200) ds_loss: 0.438 - gn_loss: 3.472 - true_out: 0.791 - fake_out: 0.133>>0.045\n",
      "(301/1200) ds_loss: 0.386 - gn_loss: 3.169 - true_out: 0.937 - fake_out: 0.238>>0.062\n",
      "(401/1200) ds_loss: 0.276 - gn_loss: 2.687 - true_out: 0.849 - fake_out: 0.084>>0.104\n",
      "(501/1200) ds_loss: 0.637 - gn_loss: 4.457 - true_out: 0.907 - fake_out: 0.364>>0.015\n",
      "(601/1200) ds_loss: 0.326 - gn_loss: 2.486 - true_out: 0.820 - fake_out: 0.096>>0.122\n",
      "(701/1200) ds_loss: 0.445 - gn_loss: 2.025 - true_out: 0.715 - fake_out: 0.066>>0.195\n",
      "(801/1200) ds_loss: 0.547 - gn_loss: 3.117 - true_out: 0.803 - fake_out: 0.219>>0.067\n",
      "(901/1200) ds_loss: 0.226 - gn_loss: 4.382 - true_out: 0.939 - fake_out: 0.135>>0.018\n",
      "(1001/1200) ds_loss: 0.245 - gn_loss: 2.876 - true_out: 0.871 - fake_out: 0.086>>0.088\n",
      "(1101/1200) ds_loss: 0.334 - gn_loss: 3.239 - true_out: 0.932 - fake_out: 0.184>>0.056\n",
      "Epoch 6/10\n",
      "(1/1200) ds_loss: 0.516 - gn_loss: 2.379 - true_out: 0.745 - fake_out: 0.123>>0.133\n",
      "(101/1200) ds_loss: 0.659 - gn_loss: 4.301 - true_out: 0.898 - fake_out: 0.379>>0.019\n",
      "(201/1200) ds_loss: 0.581 - gn_loss: 2.118 - true_out: 0.644 - fake_out: 0.070>>0.171\n",
      "(301/1200) ds_loss: 0.283 - gn_loss: 3.902 - true_out: 0.969 - fake_out: 0.205>>0.027\n",
      "(401/1200) ds_loss: 0.431 - gn_loss: 2.670 - true_out: 0.758 - fake_out: 0.093>>0.116\n",
      "(501/1200) ds_loss: 0.364 - gn_loss: 2.469 - true_out: 0.821 - fake_out: 0.128>>0.135\n",
      "(601/1200) ds_loss: 0.617 - gn_loss: 1.797 - true_out: 0.638 - fake_out: 0.049>>0.257\n",
      "(701/1200) ds_loss: 0.748 - gn_loss: 4.024 - true_out: 0.953 - fake_out: 0.405>>0.031\n",
      "(801/1200) ds_loss: 0.286 - gn_loss: 3.185 - true_out: 0.935 - fake_out: 0.171>>0.062\n",
      "(901/1200) ds_loss: 0.918 - gn_loss: 1.067 - true_out: 0.519 - fake_out: 0.105>>0.437\n",
      "(1001/1200) ds_loss: 0.202 - gn_loss: 4.011 - true_out: 0.904 - fake_out: 0.075>>0.034\n",
      "(1101/1200) ds_loss: 0.589 - gn_loss: 4.134 - true_out: 0.950 - fake_out: 0.367>>0.023\n",
      "Epoch 7/10\n",
      "(1/1200) ds_loss: 0.789 - gn_loss: 3.123 - true_out: 0.865 - fake_out: 0.380>>0.065\n",
      "(101/1200) ds_loss: 0.262 - gn_loss: 3.388 - true_out: 0.843 - fake_out: 0.070>>0.055\n",
      "(201/1200) ds_loss: 1.155 - gn_loss: 0.550 - true_out: 0.446 - fake_out: 0.106>>0.643\n",
      "(301/1200) ds_loss: 0.170 - gn_loss: 2.753 - true_out: 0.913 - fake_out: 0.068>>0.089\n",
      "(401/1200) ds_loss: 0.442 - gn_loss: 1.862 - true_out: 0.708 - fake_out: 0.045>>0.240\n",
      "(501/1200) ds_loss: 0.272 - gn_loss: 2.579 - true_out: 0.883 - fake_out: 0.119>>0.106\n",
      "(601/1200) ds_loss: 0.622 - gn_loss: 1.640 - true_out: 0.659 - fake_out: 0.041>>0.267\n",
      "(701/1200) ds_loss: 0.768 - gn_loss: 4.570 - true_out: 0.982 - fake_out: 0.434>>0.020\n",
      "(801/1200) ds_loss: 0.383 - gn_loss: 3.299 - true_out: 0.818 - fake_out: 0.128>>0.054\n",
      "(901/1200) ds_loss: 0.494 - gn_loss: 2.026 - true_out: 0.724 - fake_out: 0.111>>0.188\n",
      "(1001/1200) ds_loss: 0.456 - gn_loss: 2.040 - true_out: 0.801 - fake_out: 0.165>>0.171\n",
      "(1101/1200) ds_loss: 0.204 - gn_loss: 2.630 - true_out: 0.904 - fake_out: 0.086>>0.098\n",
      "Epoch 8/10\n",
      "(1/1200) ds_loss: 0.137 - gn_loss: 3.853 - true_out: 0.933 - fake_out: 0.061>>0.033\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "9. 学習を行う\n",
    "'''\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# 学習回数\n",
    "n_epoch = 10\n",
    "\n",
    "# 画像の保存先のパス\n",
    "# パスは環境に合わせて書き換えることが必要\n",
    "# outf = '/content/drive/MyDrive/Colab Notebooks/GAN/DCGAN_PyTorch/result'\n",
    "outf = \"result\"\n",
    "\n",
    "# エポックごとに出力する生成画像のためのノイズを生成\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size, gn_input_dim, 1, 1, device=device)  \n",
    "\n",
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, n_epoch))\n",
    "\n",
    "    # バッチデータのループ(ステップ)\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        # ミニバッチのすべての画像を取得\n",
    "        real_image = data[0].to(device)\n",
    "        # 画像の枚数を取得(バッチサイズ)\n",
    "        sample_size = real_image.size(0)\n",
    "        \n",
    "        # 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "        noise = torch.randn(sample_size, # バッチサイズ\n",
    "                            gn_input_dim,# 生成器の入力次元100\n",
    "                            1,           # 1\n",
    "                            1,           # 1\n",
    "                            device=device)\n",
    "        # オリジナル画像に対する識別信号の正解値「1」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        real_target = torch.full((sample_size,),\n",
    "                                 1.,\n",
    "                                 device=device)\n",
    "        # 生成画像に対する識別信号の正解値「0」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        fake_target = torch.full((sample_size,),\n",
    "                                 0.,\n",
    "                                 device=device) \n",
    "        \n",
    "        # -----識別器の学習-----\n",
    "        # 識別器の誤差の勾配を初期化\n",
    "        discriminator.zero_grad()    \n",
    "\n",
    "        # 識別器に画像を入力して識別信号を出力\n",
    "        output = discriminator(real_image)\n",
    "        # オリジナル画像に対する識別値の損失を取得\n",
    "        ds_real_err = criterion(output,    # オリジナル画像の識別信号\n",
    "                              real_target) # 正解ラベル(1)\n",
    "        # 1ステップ(1バッチ)におけるオリジナル画像の識別信号の平均\n",
    "        true_dsout_mean = output.mean().item()\n",
    "\n",
    "        # ノイズを生成器に入力してフェイク画像を生成\n",
    "        fake_image = generator(noise)\n",
    "        # フェイク画像を識別器に入力して識別信号を出力\n",
    "        output = discriminator(fake_image.detach())\n",
    "        # フェイク画像を偽と判定できない場合の損失\n",
    "        ds_fake_err = criterion(output,    # フェイク画像の識別信号\n",
    "                              fake_target) # 正解ラベル(偽物の0)\n",
    "        # フェイク画像の識別信号の平均\n",
    "        fake_dsout_mean1 = output.mean().item()\n",
    "        # オリジナル画像とフェイク画像に対する識別の損失を合計して\n",
    "        # 識別器としての損失を求める\n",
    "        ds_err = ds_real_err + ds_fake_err\n",
    "\n",
    "        # 識別器全体の誤差を逆伝播\n",
    "        ds_err.backward()\n",
    "        # 判別器の重みのみを更新(生成器は更新しない)\n",
    "        optimizer_ds.step()\n",
    "\n",
    "        # -----生成器の学習-----\n",
    "        # 生成器の誤差の勾配を初期化\n",
    "        generator.zero_grad()\n",
    "        # 更新した識別器に再度フェイク画像を入力して識別信号を取得\n",
    "        output = discriminator(fake_image)\n",
    "        # フェイク画像をオリジナル画像と誤認できない場合の損失\n",
    "        gn_err = criterion(output,      # フェイク画像の識別信号\n",
    "                           real_target) # 誤認させるのが目的なので正解ラベルは1\n",
    "        # 更新後の識別器の誤差を逆伝播\n",
    "        gn_err.backward() \n",
    "        # 更新後の識別器のフェイク画像に対する識別信号の平均\n",
    "        fake_dsout_mean2 = output.mean().item()\n",
    "        # 生成器の重みを更新後の識別誤差の勾配で更新\n",
    "        optimizer_gn.step()\n",
    "\n",
    "        # 100ステップごとに結果を出力\n",
    "        if itr % 100 == 0: \n",
    "            print(\n",
    "'({}/{}) ds_loss: {:.3f} - gn_loss: {:.3f} - true_out: {:.3f} - fake_out: {:.3f}>>{:.3f}'\n",
    "                  .format(\n",
    "                      itr + 1,          # ステップ数(イテレート回数)\n",
    "                      len(dataloader),  # ステップ数(1エポックのバッチ数)\n",
    "                      ds_err.item(),    # 識別器の損失\n",
    "                      gn_err.item(),    # フェイクをオリジナルと誤認しない損失\n",
    "                      true_dsout_mean,  # オリジナル画像の識別信号の平均\n",
    "                      fake_dsout_mean1, # フェイク画像の識別信号の平均\n",
    "                      fake_dsout_mean2) # 更新後識別器のフェイクの識別信号平均\n",
    "                  )\n",
    "\n",
    "        # 学習開始直後にオリジナル画像を保存する\n",
    "        if epoch == 0 and itr == 0:\n",
    "            vutils.save_image(real_image,\n",
    "                              '{}/real_samples.png'.format(outf),\n",
    "                              normalize=True,\n",
    "                              nrow=10)\n",
    "\n",
    "    # 1エポック終了ごとに生成器が生成した画像を保存\n",
    "    # バッチサイズと同じ数のノイズを生成器に入力\n",
    "    fake_image = generator(fixed_noise)\n",
    "    # 画像を保存\n",
    "    vutils.save_image(\n",
    "        fake_image.detach(),\n",
    "        '{}/generated_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "        normalize=True,\n",
    "        nrow=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN4Xrtqp9hBtIX50A8Kbh3H",
   "collapsed_sections": [],
   "mount_file_id": "1ECSIbSBGrIDcJC5Ky1h5ow1B60M_y5hm",
   "name": "DCGAN_MNIST_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
