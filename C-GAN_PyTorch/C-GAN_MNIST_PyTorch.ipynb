{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2369,
     "status": "ok",
     "timestamp": 1629012702418,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "7OhvN34JlwJr",
    "outputId": "48b18d16-d7bb-425c-e6b0-2ea18b8479cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. データセットとデータローダーを用意\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# MNISTデータセットの訓練データを用意\n",
    "dataset = datasets.MNIST(\n",
    "    # mnistフォルダーに保存\n",
    "    # パスは環境に合わせて書き換えることが必要\n",
    "    # root='/content/drive/MyDrive/Colab Notebooks/C-GAN/C-GAN_PyTorch/mnist',\n",
    "    root=\"mnist\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    # トランスフォームオブジェクトを設定\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            # データを平均0.5、標準偏差0.5の標準正規分布で正規化\n",
    "            # チャネル数は1なのでタプルの要素も1\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size = 50\n",
    "\n",
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True  # ミニバッチのサイズは50\n",
    ")  # データをシャッフルしてから抽出\n",
    "\n",
    "# 使用可能なデバイスを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: mnist\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sDIiDtXUnYTV"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. 識別器のクラスを定義 \n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"識別器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"識別器のネットワークを構築する\"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        start_ch = 128  # 先頭層の出力チャネル数\n",
    "        in_ch = 1 + 10  # 入力画像のチャネル数\n",
    "\n",
    "        # 識別器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                # 第1層: (bs, 11, 28, 28) -> (bs, 128, 14, 14)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        in_ch,  # 入力のチャネル数は1\n",
    "                        start_ch,  # フィルター数は128\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # LeakyReLU関数を適用\n",
    "                    # 負の勾配を制御する係数を0.2(デフォルトは0.01)\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第2層: (bs, 128, 14, 14) -> (bs, 256, 7, 7)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        start_ch,  # 入力のチャネル数は128\n",
    "                        start_ch * 2,  # フィルター数は128×2\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # 出力値を正規化する(チャネル数は128×2)\n",
    "                    nn.BatchNorm2d(start_ch * 2),\n",
    "                    # LeakyReLU関数を適用\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第3層: (bs, 256, 7, 7) -> (bs, 512, 3, 3)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        start_ch * 2,  # 入力のチャネル数は128×2\n",
    "                        start_ch * 4,  # フィルター数は128×4\n",
    "                        3,  # 3×3のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×4)\n",
    "                    nn.BatchNorm2d(start_ch * 4),\n",
    "                    # leaky ReLU関数を適用\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第4層: (bs, 512, 3, 3) -> (bs, 1, 1, 1)\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        start_ch * 4,  # 入力のチャネル数は128×4\n",
    "                        1,  # フィルター数は1\n",
    "                        3,  # 3×3のフィルター\n",
    "                        1,  # ストライドは1\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 最終出力にはシグモイド関数を適用\n",
    "                    nn.Sigmoid(),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          x: 画像データまたは生成画像\n",
    "        \"\"\"\n",
    "        # 識別器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        # 出力されたテンソルの形状をフラット(bs,)にする\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "wxyecq_1nTj1"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. 生成器のクラスを定義\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"生成器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"生成器のネットワークを構築する\"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        input_dim = 100 + 10  # 入力データの次元\n",
    "        out_ch = 128  # 最終層のチャネル数\n",
    "        img_ch = 1  # 生成画像のチャネル数\n",
    "\n",
    "        # 生成器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                # 第1層: (bs, 110, 1, 1) -> (bs, 512, 3, 3)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        input_dim,  # 入力のチャネル数は100\n",
    "                        out_ch * 4,  # フィルター数は128×4\n",
    "                        3,  # 3×3のフィルター\n",
    "                        1,  # ストライドは1\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×4)\n",
    "                    nn.BatchNorm2d(out_ch * 4),\n",
    "                    # ReLU関数を適用\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "                # 第2層: (bs, 512, 3, 3) -> (bs, 256, 7, 7)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        out_ch * 4,  # 入力のチャネル数は128×4\n",
    "                        out_ch * 2,  # フィルター数は128×2\n",
    "                        3,  # 3×3のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×2)\n",
    "                    nn.BatchNorm2d(out_ch * 2),\n",
    "                    # ReLU関数を適用\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "                # 第3層: (bs, 256, 7, 7) -> (bs, 128, 14, 14)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        out_ch * 2,  # 入力のチャネル数は128×2\n",
    "                        out_ch,  # フィルター数は128\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # 出力値を正規化する(チャネル数は128)\n",
    "                    nn.BatchNorm2d(out_ch),\n",
    "                    # ReLU関数を適用\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "                # 第4層: (bs, 128, 14, 14) -> (bs, 1, 28, 28)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(\n",
    "                        out_ch,  # 入力のチャネル数は128\n",
    "                        img_ch,  # フィルター数は1\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # Tanh関数を適用\n",
    "                    nn.Tanh(),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          z: 識別器の出力\n",
    "        \"\"\"\n",
    "        # 生成器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hgiP3bPGncbM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. 重みの初期化を行う関数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    ネットワークの重みを正規分布からサンプリングした値で初期化する\n",
    "\n",
    "    Parameters:\n",
    "      m: ネットワークのインスタンス\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    # 畳み込み層の重み\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)  # 平均0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0)  # バイアスのみ0で初期化\n",
    "    # バッチ正規化層の重み\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)  # 平均1.0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0)  # バイアスのみ0で初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3804,
     "status": "ok",
     "timestamp": 1627730198814,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "f7VJAquMnf36",
    "outputId": "7aff3deb-6e9d-4dc6-c71a-7d5325c56a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 512, 3, 3]         507,392\n",
      "       BatchNorm2d-2            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-3            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-4            [-1, 256, 7, 7]       1,179,904\n",
      "       BatchNorm2d-5            [-1, 256, 7, 7]             512\n",
      "              ReLU-6            [-1, 256, 7, 7]               0\n",
      "   ConvTranspose2d-7          [-1, 128, 14, 14]         524,416\n",
      "       BatchNorm2d-8          [-1, 128, 14, 14]             256\n",
      "              ReLU-9          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-10            [-1, 1, 28, 28]           2,049\n",
      "             Tanh-11            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 2,215,553\n",
      "Trainable params: 2,215,553\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 8.45\n",
      "Estimated Total Size (MB): 9.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. 生成器をインスタンス化して重みを初期化する\n",
    "\"\"\"\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "# 生成器をインスタンス化\n",
    "generator = Generator().to(device)\n",
    "# 重みを初期化\n",
    "generator.apply(weights_init)\n",
    "# 生成器のサマリを出力\n",
    "torchsummary.summary(generator, (110, 1, 1))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1627730198815,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "yhSIPXkqnmNc",
    "outputId": "f4615728-92f1-4602-d3d0-a2db60cd18b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 14, 14]          22,656\n",
      "         LeakyReLU-2          [-1, 128, 14, 14]               0\n",
      "            Conv2d-3            [-1, 256, 7, 7]         524,544\n",
      "       BatchNorm2d-4            [-1, 256, 7, 7]             512\n",
      "         LeakyReLU-5            [-1, 256, 7, 7]               0\n",
      "            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "         LeakyReLU-8            [-1, 512, 3, 3]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           4,609\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,733,505\n",
      "Trainable params: 1,733,505\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.78\n",
      "Params size (MB): 6.61\n",
      "Estimated Total Size (MB): 7.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "6. 識別器をインスタンス化して重みを初期化する\n",
    "\"\"\"\n",
    "\n",
    "# 識別器をインスタンス化\n",
    "discriminator = Discriminator().to(device)\n",
    "# 重みを初期化\n",
    "discriminator.apply(weights_init)\n",
    "# 識別器のサマリを出力\n",
    "torchsummary.summary(discriminator, (11, 28, 28))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0XIwXN38nuaA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "7. 損失関数とオプティマイザーの設定\n",
    "\"\"\"\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# 損失関数はバイナリクロスエントロピー誤差\n",
    "criterion = nn.BCELoss()\n",
    "# 識別器のオプティマイザ−を設定\n",
    "optimizer_ds = optim.Adam(discriminator.parameters(), lr=0.0003)  # 学習率: デフォルトは0.001\n",
    "# 生成器のオプティマイザーを設定\n",
    "optimizer_gn = optim.Adam(generator.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "q2qf1mp2nx_g"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8. 正解ラベルをOne-hot化する関数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def encoder(label, device, n_class=10):\n",
    "    \"\"\"正解ラベルをOne-hot表現に変換する\n",
    "    Parameters:\n",
    "      label: 変換対象の正解ラベル\n",
    "      device: 使用するデバイス\n",
    "      n_class: 分類先のクラス数\n",
    "    \"\"\"\n",
    "    # 対角成分の値が1の対角行列を作成\n",
    "    # 2階テンソル(クラスの数, クラスの数)が作成される\n",
    "    one_hot = torch.eye(n_class, device=device)\n",
    "    # ラベルの値のインデックスのOne-hot表現を抽出し、\n",
    "    # 生成器が入力する(バッチサイズ, クラス数, 1, 1)の形状にして返す\n",
    "    return one_hot[label].view(-1, n_class, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BzkqmHPrn2nS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "9. 画像のテンソルとラベルのテンソルを結合する関数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def concat_img_label(image, label, device, n_class=10):\n",
    "    \"\"\"画像のテンソルとラベルのテンソルを連結して\n",
    "       識別器に入力するテンソルを作成する\n",
    "\n",
    "    Parameters:\n",
    "      image: 画像データを格納したテンソル(bs, 1, 28, 28)\n",
    "      label: 正解ラベル\n",
    "      device: 使用可能なデバイス\n",
    "      n_class: 分類先のクラス数\n",
    "    Return:\n",
    "      画像とOne-hot化ラベルを結合したテンソル\n",
    "      (bs, 11, 28, 28)\n",
    "    \"\"\"\n",
    "    # 画像が格納されたテンソルの形状を取得する\n",
    "    bs, ch, h, w = image.shape\n",
    "    # ラベルをOne-hot表現に変換\n",
    "    oh_label = encoder(label, device)\n",
    "    # 画像のサイズに合わせて正解ラベルを(bs, 10, 28, 28)に拡張する\n",
    "    oh_label = oh_label.expand(bs, n_class, h, w)\n",
    "    # 画像(bs, 1(チャネル), 28, 28)とチャネル方向(dim=1)で結合して戻り値とする\n",
    "    return torch.cat((image, oh_label), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wudp4WDyn6to"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "10. ノイズのテンソルとラベルのテンソルを連結する関数\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def concat_noise_label(noise, label, device):\n",
    "    \"\"\"ノイズのテンソルとラベルのテンソルを連結して\n",
    "       生成器に入力するテンソルを作成する\n",
    "\n",
    "    Parameters:\n",
    "      noise(Tensor): ノイズのテンソル(bs, 100, 1, 1)\n",
    "      label(int): 正解ラベル\n",
    "      device: 使用するデバイス\n",
    "    Return:\n",
    "      ノイズとOne-hot化ラベルを連結したテンソル\n",
    "      (bs, 110, 1, 1)\n",
    "    \"\"\"\n",
    "    # ラベルをOne-hot化\n",
    "    oh_label = encoder(label, device)\n",
    "    # ノイズ(bs, 100, 1, 1)とOne-hot化ラベルを\n",
    "    # dim=1で連結して戻り値とする\n",
    "    return torch.cat((noise, oh_label), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8LDhMqVRQlWS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "11. エポックごとの画像生成に使用するノイズのテンソルを作成\n",
    "\"\"\"\n",
    "\n",
    "# ノイズの次元数\n",
    "noise_num = 100\n",
    "\n",
    "# 生成器のエポックごとの画像生成に使用するノイズのテンソルを作成\n",
    "# バッチデータと同じ数だけ作成(bs, 100, 1, 1)\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size, noise_num, 1, 1, device=device  # バッチサイズ  # ノイズの次元100  # 1  # 1\n",
    ")\n",
    "# 正解ラベル0～9をバッチデータの数だけ繰り返す\n",
    "# 配列の要素数はバッチデータの数と同じ\n",
    "fixed_label = [i for i in range(10)] * (batch_size // 10)\n",
    "# ノイズ用の正解ラベルを1階テンソルに変換: (bs,)\n",
    "fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n",
    "# ノイズ(bs, 100, 1, 1)とOne-hot化したラベル(バッチサイズ, クラス数, 1, 1)を\n",
    "# 連結したテンソル (bs, 110, 1, 1)を作成\n",
    "fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. 学習を行う\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 464295,
     "status": "ok",
     "timestamp": 1627730795888,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "UAYdTff3oCGZ",
    "outputId": "61337de4-9074-4774-f05e-05a21012934a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(1/1200) ds_loss: 1.618 - gn_loss: 2.383 - true_out: 0.447 - fake_out: 0.489>>0.295\n",
      "(101/1200) ds_loss: 0.005 - gn_loss: 7.826 - true_out: 0.998 - fake_out: 0.003>>0.001\n",
      "(201/1200) ds_loss: 0.004 - gn_loss: 8.574 - true_out: 0.998 - fake_out: 0.002>>0.001\n",
      "(301/1200) ds_loss: 0.167 - gn_loss: 8.366 - true_out: 0.969 - fake_out: 0.048>>0.012\n",
      "(401/1200) ds_loss: 0.090 - gn_loss: 6.489 - true_out: 1.000 - fake_out: 0.048>>0.024\n",
      "(501/1200) ds_loss: 0.048 - gn_loss: 8.627 - true_out: 0.970 - fake_out: 0.004>>0.001\n",
      "(601/1200) ds_loss: 0.015 - gn_loss: 7.789 - true_out: 0.992 - fake_out: 0.006>>0.006\n",
      "(701/1200) ds_loss: 0.094 - gn_loss: 8.533 - true_out: 0.972 - fake_out: 0.027>>0.003\n",
      "(801/1200) ds_loss: 0.044 - gn_loss: 9.665 - true_out: 0.984 - fake_out: 0.025>>0.000\n",
      "(901/1200) ds_loss: 0.027 - gn_loss: 6.589 - true_out: 0.992 - fake_out: 0.017>>0.009\n",
      "(1001/1200) ds_loss: 0.103 - gn_loss: 7.839 - true_out: 0.965 - fake_out: 0.044>>0.002\n",
      "(1101/1200) ds_loss: 0.067 - gn_loss: 7.381 - true_out: 0.973 - fake_out: 0.017>>0.011\n",
      "Epoch 2/10\n",
      "(1/1200) ds_loss: 0.051 - gn_loss: 7.936 - true_out: 0.980 - fake_out: 0.021>>0.004\n",
      "(101/1200) ds_loss: 0.027 - gn_loss: 8.421 - true_out: 0.985 - fake_out: 0.003>>0.001\n",
      "(201/1200) ds_loss: 0.058 - gn_loss: 6.755 - true_out: 0.962 - fake_out: 0.013>>0.009\n",
      "(301/1200) ds_loss: 0.011 - gn_loss: 9.732 - true_out: 0.991 - fake_out: 0.002>>0.001\n",
      "(401/1200) ds_loss: 0.186 - gn_loss: 6.547 - true_out: 0.958 - fake_out: 0.089>>0.012\n",
      "(501/1200) ds_loss: 0.094 - gn_loss: 5.893 - true_out: 0.979 - fake_out: 0.058>>0.019\n",
      "(601/1200) ds_loss: 0.473 - gn_loss: 4.591 - true_out: 0.755 - fake_out: 0.017>>0.061\n",
      "(701/1200) ds_loss: 0.186 - gn_loss: 6.419 - true_out: 0.943 - fake_out: 0.070>>0.010\n",
      "(801/1200) ds_loss: 0.175 - gn_loss: 4.699 - true_out: 0.964 - fake_out: 0.097>>0.047\n",
      "(901/1200) ds_loss: 0.438 - gn_loss: 5.004 - true_out: 0.810 - fake_out: 0.085>>0.071\n",
      "(1001/1200) ds_loss: 0.117 - gn_loss: 4.742 - true_out: 0.938 - fake_out: 0.040>>0.028\n",
      "(1101/1200) ds_loss: 0.213 - gn_loss: 4.269 - true_out: 0.969 - fake_out: 0.115>>0.087\n",
      "Epoch 3/10\n",
      "(1/1200) ds_loss: 0.047 - gn_loss: 5.475 - true_out: 0.983 - fake_out: 0.028>>0.013\n",
      "(101/1200) ds_loss: 0.470 - gn_loss: 2.805 - true_out: 0.944 - fake_out: 0.192>>0.170\n",
      "(201/1200) ds_loss: 0.392 - gn_loss: 3.363 - true_out: 0.948 - fake_out: 0.210>>0.114\n",
      "(301/1200) ds_loss: 0.340 - gn_loss: 4.824 - true_out: 0.913 - fake_out: 0.157>>0.054\n",
      "(401/1200) ds_loss: 0.523 - gn_loss: 3.082 - true_out: 0.733 - fake_out: 0.093>>0.094\n",
      "(501/1200) ds_loss: 0.228 - gn_loss: 4.121 - true_out: 0.894 - fake_out: 0.071>>0.069\n",
      "(601/1200) ds_loss: 0.518 - gn_loss: 3.245 - true_out: 0.749 - fake_out: 0.085>>0.104\n",
      "(701/1200) ds_loss: 0.198 - gn_loss: 3.874 - true_out: 0.918 - fake_out: 0.083>>0.054\n",
      "(801/1200) ds_loss: 0.766 - gn_loss: 6.048 - true_out: 0.622 - fake_out: 0.026>>0.015\n",
      "(901/1200) ds_loss: 0.550 - gn_loss: 3.130 - true_out: 0.906 - fake_out: 0.257>>0.132\n",
      "(1001/1200) ds_loss: 1.625 - gn_loss: 2.866 - true_out: 0.407 - fake_out: 0.169>>0.177\n",
      "(1101/1200) ds_loss: 0.384 - gn_loss: 4.391 - true_out: 0.799 - fake_out: 0.082>>0.065\n",
      "Epoch 4/10\n",
      "(1/1200) ds_loss: 0.328 - gn_loss: 3.708 - true_out: 0.919 - fake_out: 0.156>>0.095\n",
      "(101/1200) ds_loss: 1.221 - gn_loss: 2.575 - true_out: 0.478 - fake_out: 0.149>>0.205\n",
      "(201/1200) ds_loss: 0.526 - gn_loss: 3.366 - true_out: 0.783 - fake_out: 0.122>>0.095\n",
      "(301/1200) ds_loss: 0.390 - gn_loss: 3.622 - true_out: 0.817 - fake_out: 0.098>>0.060\n",
      "(401/1200) ds_loss: 0.766 - gn_loss: 2.632 - true_out: 0.726 - fake_out: 0.223>>0.170\n",
      "(501/1200) ds_loss: 0.314 - gn_loss: 3.109 - true_out: 0.892 - fake_out: 0.101>>0.103\n",
      "(601/1200) ds_loss: 0.602 - gn_loss: 3.379 - true_out: 0.810 - fake_out: 0.198>>0.127\n",
      "(701/1200) ds_loss: 0.523 - gn_loss: 2.420 - true_out: 0.835 - fake_out: 0.209>>0.197\n",
      "(801/1200) ds_loss: 0.937 - gn_loss: 2.201 - true_out: 0.631 - fake_out: 0.168>>0.222\n",
      "(901/1200) ds_loss: 1.154 - gn_loss: 2.561 - true_out: 0.596 - fake_out: 0.261>>0.170\n",
      "(1001/1200) ds_loss: 0.709 - gn_loss: 2.849 - true_out: 0.741 - fake_out: 0.177>>0.147\n",
      "(1101/1200) ds_loss: 0.579 - gn_loss: 2.088 - true_out: 0.838 - fake_out: 0.233>>0.229\n",
      "Epoch 5/10\n",
      "(1/1200) ds_loss: 1.018 - gn_loss: 1.707 - true_out: 0.794 - fake_out: 0.426>>0.287\n",
      "(101/1200) ds_loss: 0.884 - gn_loss: 2.970 - true_out: 0.680 - fake_out: 0.223>>0.135\n",
      "(201/1200) ds_loss: 0.944 - gn_loss: 1.995 - true_out: 0.584 - fake_out: 0.157>>0.236\n",
      "(301/1200) ds_loss: 0.865 - gn_loss: 1.863 - true_out: 0.645 - fake_out: 0.217>>0.244\n",
      "(401/1200) ds_loss: 1.092 - gn_loss: 1.742 - true_out: 0.610 - fake_out: 0.265>>0.294\n",
      "(501/1200) ds_loss: 2.243 - gn_loss: 1.207 - true_out: 0.579 - fake_out: 0.614>>0.430\n",
      "(601/1200) ds_loss: 0.607 - gn_loss: 2.386 - true_out: 0.793 - fake_out: 0.245>>0.171\n",
      "(701/1200) ds_loss: 1.013 - gn_loss: 1.367 - true_out: 0.850 - fake_out: 0.469>>0.347\n",
      "(801/1200) ds_loss: 1.250 - gn_loss: 1.879 - true_out: 0.493 - fake_out: 0.256>>0.232\n",
      "(901/1200) ds_loss: 1.325 - gn_loss: 1.079 - true_out: 0.807 - fake_out: 0.543>>0.432\n",
      "(1001/1200) ds_loss: 0.429 - gn_loss: 2.406 - true_out: 0.835 - fake_out: 0.182>>0.156\n",
      "(1101/1200) ds_loss: 0.612 - gn_loss: 2.467 - true_out: 0.782 - fake_out: 0.205>>0.152\n",
      "Epoch 6/10\n",
      "(1/1200) ds_loss: 1.014 - gn_loss: 2.029 - true_out: 0.710 - fake_out: 0.307>>0.261\n",
      "(101/1200) ds_loss: 0.827 - gn_loss: 1.791 - true_out: 0.745 - fake_out: 0.279>>0.240\n",
      "(201/1200) ds_loss: 0.831 - gn_loss: 1.481 - true_out: 0.775 - fake_out: 0.371>>0.289\n",
      "(301/1200) ds_loss: 0.885 - gn_loss: 1.297 - true_out: 0.858 - fake_out: 0.406>>0.388\n",
      "(401/1200) ds_loss: 1.275 - gn_loss: 1.504 - true_out: 0.557 - fake_out: 0.350>>0.325\n",
      "(501/1200) ds_loss: 0.884 - gn_loss: 1.912 - true_out: 0.789 - fake_out: 0.358>>0.246\n",
      "(601/1200) ds_loss: 1.252 - gn_loss: 0.946 - true_out: 0.798 - fake_out: 0.510>>0.505\n",
      "(701/1200) ds_loss: 0.614 - gn_loss: 2.265 - true_out: 0.819 - fake_out: 0.249>>0.173\n",
      "(801/1200) ds_loss: 0.999 - gn_loss: 1.567 - true_out: 0.611 - fake_out: 0.278>>0.290\n",
      "(901/1200) ds_loss: 1.447 - gn_loss: 1.243 - true_out: 0.681 - fake_out: 0.503>>0.399\n",
      "(1001/1200) ds_loss: 0.905 - gn_loss: 1.245 - true_out: 0.837 - fake_out: 0.443>>0.367\n",
      "(1101/1200) ds_loss: 1.256 - gn_loss: 0.883 - true_out: 0.661 - fake_out: 0.474>>0.475\n",
      "Epoch 7/10\n",
      "(1/1200) ds_loss: 1.379 - gn_loss: 1.341 - true_out: 0.789 - fake_out: 0.568>>0.354\n",
      "(101/1200) ds_loss: 1.136 - gn_loss: 1.743 - true_out: 0.475 - fake_out: 0.164>>0.244\n",
      "(201/1200) ds_loss: 1.019 - gn_loss: 2.498 - true_out: 0.511 - fake_out: 0.156>>0.124\n",
      "(301/1200) ds_loss: 0.858 - gn_loss: 1.490 - true_out: 0.791 - fake_out: 0.379>>0.313\n",
      "(401/1200) ds_loss: 1.098 - gn_loss: 1.189 - true_out: 0.672 - fake_out: 0.439>>0.366\n",
      "(501/1200) ds_loss: 0.998 - gn_loss: 1.362 - true_out: 0.670 - fake_out: 0.382>>0.310\n",
      "(601/1200) ds_loss: 1.279 - gn_loss: 1.625 - true_out: 0.483 - fake_out: 0.260>>0.286\n",
      "(701/1200) ds_loss: 0.901 - gn_loss: 1.826 - true_out: 0.663 - fake_out: 0.288>>0.237\n",
      "(801/1200) ds_loss: 1.014 - gn_loss: 1.235 - true_out: 0.647 - fake_out: 0.366>>0.352\n",
      "(901/1200) ds_loss: 1.297 - gn_loss: 0.975 - true_out: 0.567 - fake_out: 0.428>>0.436\n",
      "(1001/1200) ds_loss: 1.309 - gn_loss: 1.801 - true_out: 0.471 - fake_out: 0.247>>0.235\n",
      "(1101/1200) ds_loss: 1.451 - gn_loss: 1.317 - true_out: 0.435 - fake_out: 0.308>>0.320\n",
      "Epoch 8/10\n",
      "(1/1200) ds_loss: 1.072 - gn_loss: 1.482 - true_out: 0.677 - fake_out: 0.398>>0.307\n",
      "(101/1200) ds_loss: 1.143 - gn_loss: 1.340 - true_out: 0.588 - fake_out: 0.356>>0.352\n",
      "(201/1200) ds_loss: 0.570 - gn_loss: 2.040 - true_out: 0.794 - fake_out: 0.239>>0.192\n",
      "(301/1200) ds_loss: 0.850 - gn_loss: 1.743 - true_out: 0.646 - fake_out: 0.260>>0.226\n",
      "(401/1200) ds_loss: 1.607 - gn_loss: 1.512 - true_out: 0.410 - fake_out: 0.330>>0.296\n",
      "(501/1200) ds_loss: 1.540 - gn_loss: 0.895 - true_out: 0.559 - fake_out: 0.524>>0.473\n",
      "(601/1200) ds_loss: 1.169 - gn_loss: 1.463 - true_out: 0.501 - fake_out: 0.273>>0.294\n",
      "(701/1200) ds_loss: 0.837 - gn_loss: 1.241 - true_out: 0.793 - fake_out: 0.396>>0.349\n",
      "(801/1200) ds_loss: 0.954 - gn_loss: 0.981 - true_out: 0.770 - fake_out: 0.444>>0.424\n",
      "(901/1200) ds_loss: 1.566 - gn_loss: 0.717 - true_out: 0.634 - fake_out: 0.578>>0.563\n",
      "(1001/1200) ds_loss: 0.892 - gn_loss: 1.876 - true_out: 0.602 - fake_out: 0.246>>0.208\n",
      "(1101/1200) ds_loss: 1.766 - gn_loss: 0.556 - true_out: 0.641 - fake_out: 0.649>>0.617\n",
      "Epoch 9/10\n",
      "(1/1200) ds_loss: 1.295 - gn_loss: 0.776 - true_out: 0.747 - fake_out: 0.567>>0.508\n",
      "(101/1200) ds_loss: 0.896 - gn_loss: 1.536 - true_out: 0.671 - fake_out: 0.303>>0.279\n",
      "(201/1200) ds_loss: 0.957 - gn_loss: 1.100 - true_out: 0.746 - fake_out: 0.427>>0.411\n",
      "(301/1200) ds_loss: 1.485 - gn_loss: 0.798 - true_out: 0.706 - fake_out: 0.599>>0.517\n",
      "(401/1200) ds_loss: 1.473 - gn_loss: 0.823 - true_out: 0.748 - fake_out: 0.615>>0.489\n",
      "(501/1200) ds_loss: 1.340 - gn_loss: 1.871 - true_out: 0.405 - fake_out: 0.228>>0.185\n",
      "(601/1200) ds_loss: 0.856 - gn_loss: 1.222 - true_out: 0.767 - fake_out: 0.394>>0.353\n",
      "(701/1200) ds_loss: 1.341 - gn_loss: 1.075 - true_out: 0.526 - fake_out: 0.406>>0.387\n",
      "(801/1200) ds_loss: 1.554 - gn_loss: 1.051 - true_out: 0.507 - fake_out: 0.457>>0.430\n",
      "(901/1200) ds_loss: 1.102 - gn_loss: 1.647 - true_out: 0.545 - fake_out: 0.270>>0.255\n",
      "(1001/1200) ds_loss: 1.624 - gn_loss: 0.984 - true_out: 0.425 - fake_out: 0.424>>0.420\n",
      "(1101/1200) ds_loss: 1.249 - gn_loss: 1.025 - true_out: 0.571 - fake_out: 0.428>>0.401\n",
      "Epoch 10/10\n",
      "(1/1200) ds_loss: 1.422 - gn_loss: 0.689 - true_out: 0.706 - fake_out: 0.586>>0.546\n",
      "(101/1200) ds_loss: 0.922 - gn_loss: 1.754 - true_out: 0.571 - fake_out: 0.224>>0.210\n",
      "(201/1200) ds_loss: 1.102 - gn_loss: 1.341 - true_out: 0.654 - fake_out: 0.410>>0.325\n",
      "(301/1200) ds_loss: 2.067 - gn_loss: 0.445 - true_out: 0.627 - fake_out: 0.750>>0.665\n",
      "(401/1200) ds_loss: 1.226 - gn_loss: 1.103 - true_out: 0.586 - fake_out: 0.432>>0.387\n",
      "(501/1200) ds_loss: 1.338 - gn_loss: 1.342 - true_out: 0.516 - fake_out: 0.391>>0.320\n",
      "(601/1200) ds_loss: 0.961 - gn_loss: 1.895 - true_out: 0.536 - fake_out: 0.196>>0.195\n",
      "(701/1200) ds_loss: 0.925 - gn_loss: 1.538 - true_out: 0.603 - fake_out: 0.267>>0.270\n",
      "(801/1200) ds_loss: 1.507 - gn_loss: 1.183 - true_out: 0.386 - fake_out: 0.321>>0.348\n",
      "(901/1200) ds_loss: 1.240 - gn_loss: 0.852 - true_out: 0.621 - fake_out: 0.458>>0.463\n",
      "(1001/1200) ds_loss: 0.999 - gn_loss: 1.563 - true_out: 0.580 - fake_out: 0.283>>0.255\n",
      "(1101/1200) ds_loss: 1.136 - gn_loss: 1.111 - true_out: 0.561 - fake_out: 0.366>>0.369\n",
      "CPU times: user 7min 13s, sys: 1.56 s, total: 7min 14s\n",
      "Wall time: 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "n_epoch = 10  # 学習回数\n",
    "\n",
    "# 画像の保存先のパス\n",
    "# パスは環境に合わせて書き換えることが必要\n",
    "# outf = '/content/drive/MyDrive/Colab Notebooks/C-GAN/C-GAN_PyTorch/result'\n",
    "# outf = \"result\"\n",
    "outf = \"/home/a6000/github/pilot-GAN/C-GAN_PyTorch/result\"\n",
    "\n",
    "# save initial image (should be random noise)\n",
    "fake_image = generator(fixed_noise_label)\n",
    "vutils.save_image(\n",
    "    fake_image.detach(),\n",
    "    \"{}/fake_samples_epoch_{:03d}.png\".format(outf, 0),\n",
    "    normalize=True,\n",
    "    nrow=10,\n",
    ")\n",
    "\n",
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, n_epoch))\n",
    "\n",
    "    # バッチデータのループ(ステップ)\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        # ミニバッチのすべての画像を取得\n",
    "        real_image = data[0].to(device)\n",
    "        # ミニバッチのすべての正解ラベルを取得\n",
    "        real_label = data[1].to(device)\n",
    "        # 画像とOne-hot化したラベルを連結したテンソルを取得\n",
    "        # (bs, 11, 28, 28)\n",
    "        real_image_label = concat_img_label(real_image, real_label, device)  # 画像  # 正解ラベル\n",
    "        # 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "        noise = torch.randn(\n",
    "            batch_size, noise_num, 1, 1, device=device  # バッチサイズ  # ノイズの次元100  # 1  # 1\n",
    "        )\n",
    "        # フェイク画像用の正解ラベルを生成: 出力(bs,)\n",
    "        fake_label = torch.randint(\n",
    "            10,  # 0～9のラベルを生成\n",
    "            (batch_size,),  # バッチデータの数だけ生成\n",
    "            dtype=torch.long,\n",
    "            device=device,\n",
    "        )\n",
    "        # ノイズとフェイクのラベルを連結: (bs, 110, 1, 1)\n",
    "        fake_noise_label = concat_noise_label(\n",
    "            noise, fake_label, device  # (bs, 100, 1, 1)  # (bs,)\n",
    "        )\n",
    "        # オリジナル画像に対する識別信号の正解値「1」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        real_target = torch.full((batch_size,), 1.0, device=device)\n",
    "        # 生成画像に対する識別信号の正解値「0」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        fake_target = torch.full((batch_size,), 0.0, device=device)\n",
    "\n",
    "        # -----識別器の学習-----\n",
    "        # 識別器の誤差の勾配を初期化\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # 識別器に画像とラベルのセットを入力して識別信号を出力\n",
    "        output = discriminator(real_image_label)\n",
    "        # オリジナル画像に対する識別値の損失を取得\n",
    "        ds_real_err = criterion(output, real_target)\n",
    "        # 1ステップ(1バッチ)におけるオリジナル画像の識別信号の平均\n",
    "        true_dsout_mean = output.mean().item()\n",
    "\n",
    "        # ノイズとフェイクのラベルを生成器に入力してフェイク画像を生成\n",
    "        # (bs, 1, 28, 28)\n",
    "        fake_image = generator(fake_noise_label)  # (bs, 110, 1, 1)\n",
    "        # フェイク画像とフェイクのラベルを連結: (bs, 11, 28, 28)\n",
    "        fake_image_label = concat_img_label(\n",
    "            fake_image, fake_label, device  # (bs, 1, 28, 28)  # (bs,)\n",
    "        )\n",
    "\n",
    "        # フェイク画像とフェイクラベルを識別器に入力して識別信号を出力\n",
    "        output = discriminator(fake_image_label.detach())\n",
    "        # フェイク画像を偽と判定できない場合の損失\n",
    "        ds_fake_err = criterion(\n",
    "            output, fake_target  # フェイク画像の識別信号\n",
    "        )  # 正解ラベル(偽物の0)\n",
    "        # フェイク画像の識別信号の平均\n",
    "        fake_dsout_mean1 = output.mean().item()\n",
    "        # オリジナル画像とフェイク画像に対する識別の損失を合計して\n",
    "        # 識別器としての損失を求める\n",
    "        ds_err = ds_real_err + ds_fake_err\n",
    "\n",
    "        # 識別器全体の誤差を逆伝播\n",
    "        ds_err.backward()\n",
    "        # 判別器の重みのみを更新(生成器は更新しない)\n",
    "        optimizer_ds.step()\n",
    "\n",
    "        # -----生成器の学習-----\n",
    "        # 生成器の誤差の勾配を初期化\n",
    "        generator.zero_grad()\n",
    "        # 更新後の識別器に再度フェイク画像とフェイクラベルを入力して識別信号を取得\n",
    "        output = discriminator(fake_image_label)\n",
    "        # フェイク画像をオリジナル画像と誤認できない場合の損失\n",
    "        gn_err = criterion(\n",
    "            output, real_target  # フェイク画像の識別信号\n",
    "        )  # 誤認させるのが目的なので正解ラベルは1\n",
    "        # 更新後の識別器の誤差を逆伝播\n",
    "        gn_err.backward()\n",
    "        # 更新後の識別器のフェイク画像に対する識別信号の平均\n",
    "        fake_dsout_mean2 = output.mean().item()\n",
    "        # 生成器の重みを更新後の識別誤差の勾配で更新\n",
    "        optimizer_gn.step()\n",
    "\n",
    "        # 100ステップごとに出力\n",
    "        if itr % 100 == 0:\n",
    "            print(\n",
    "                \"({}/{}) ds_loss: {:.3f} - gn_loss: {:.3f} - true_out: {:.3f} - fake_out: {:.3f}>>{:.3f}\".format(\n",
    "                    itr + 1,  # ステップ数(イテレート回数)\n",
    "                    len(dataloader),  # ステップ数(1エポックのバッチ数)\n",
    "                    ds_err.item(),  # 識別器の損失\n",
    "                    gn_err.item(),  # フェイクをオリジナルと誤認しない損失\n",
    "                    true_dsout_mean,  # オリジナル画像の識別信号の平均\n",
    "                    fake_dsout_mean1,  # フェイク画像の識別信号の平均\n",
    "                    fake_dsout_mean2,\n",
    "                )  # 更新後識別器のフェイクの識別信号平均\n",
    "            )\n",
    "\n",
    "        # 学習開始直後にオリジナル画像を保存する\n",
    "        if epoch == 0 and itr == 0:\n",
    "            vutils.save_image(\n",
    "                real_image, \"{}/real_samples.png\".format(outf), normalize=True, nrow=10\n",
    "            )\n",
    "\n",
    "    # 確認用画像の生成\n",
    "    # 1エポック終了ごとに確認用の生成画像を生成する\n",
    "    fake_image = generator(fixed_noise_label)\n",
    "    vutils.save_image(\n",
    "        fake_image.detach(),\n",
    "        \"{}/fake_samples_epoch_{:03d}.png\".format(outf, epoch + 1),\n",
    "        normalize=True,\n",
    "        nrow=10,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoE4FLY/QwY2OJzNGYCtES",
   "collapsed_sections": [],
   "mount_file_id": "1yyNwZ-FkZlnt0F5_clgAxZb33ujtaxV9",
   "name": "C-GAN_MNIST_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
