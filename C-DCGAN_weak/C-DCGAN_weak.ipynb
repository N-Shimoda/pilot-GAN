{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN for CIFAR 10-like images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import ConcatDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2369,
     "status": "ok",
     "timestamp": 1629012702418,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "7OhvN34JlwJr",
    "outputId": "48b18d16-d7bb-425c-e6b0-2ea18b8479cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Download and load the CIFAR-100 training & test dataset\n",
    "# root = \"/home/a6000/github/pilot-GAN/C-GAN-Color/cifar100\"\n",
    "root = \"/home/a6000/github/pilot-GAN/C-DCGAN_revised/cifar10\"\n",
    "data_transforms = transforms.Compose(\n",
    "    [\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = datasets.CIFAR10(root, train=True, download=True, transform=data_transforms)\n",
    "# test_dataset = datasets.CIFAR100(root, train=False, download=True, transform=data_transforms)\n",
    "\n",
    "# Combine the training and test datasets\n",
    "# dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# ミニバッチのサイズ\n",
    "batch_size = 50\n",
    "\n",
    "# 訓練データをセットしたデータローダーを作成する\n",
    "dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,  # ミニバッチのサイズは50\n",
    "    shuffle=True,  # データをシャッフルしてから抽出\n",
    ")\n",
    "\n",
    "# 使用可能なデバイスを確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: /home/a6000/github/pilot-GAN/C-DCGAN_revised/cifar10\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n",
      "10 Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "print(train_dataset)\n",
    "print(\"{} Classes: {}\".format(num_classes, train_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Design C-DCGAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"識別器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"\n",
    "        識別器のネットワークを構築する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes: int\n",
    "            Number of classes.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        start_ch = 128  # 先頭層の出力チャネル数\n",
    "        in_ch = 3 + num_classes  # 入力画像のチャネル数 = 3(RGB) + クラス数\n",
    "\n",
    "        # 識別器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                # 第1層: (bs, 1, 28, 28) -> (bs, 128, 14, 14)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        in_ch,  # 入力のチャネル数は1\n",
    "                        start_ch,  # フィルター数は128\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # LeakyReLU関数を適用\n",
    "                    # 論文に従って負の勾配を制御する係数を\n",
    "                    # 0.2(デフォルトは0.01)に設定\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第2層: (bs, 128, 14, 14) -> (bs, 256, 7, 7)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        start_ch,  # 入力のチャネル数は128\n",
    "                        start_ch * 2,  # フィルター数は128×2\n",
    "                        4,  # 4×4のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        1,\n",
    "                    ),  # 上下左右にサイズ1のパディング\n",
    "                    # 出力値を正規化する(チャネル数は128×2)\n",
    "                    nn.BatchNorm2d(start_ch * 2),\n",
    "                    # LeakyReLU関数を適用\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第3層: (bs, 256, 7, 7) -> (bs, 512, 3, 3)\n",
    "                nn.Sequential(\n",
    "                    # 畳み込み\n",
    "                    nn.Conv2d(\n",
    "                        start_ch * 2,  # 入力のチャネル数は128×2\n",
    "                        start_ch * 4,  # フィルター数は128×4\n",
    "                        3,  # 3×3のフィルター\n",
    "                        2,  # ストライドは2\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 出力値を正規化する(チャネル数は128×4)\n",
    "                    nn.BatchNorm2d(start_ch * 4),\n",
    "                    # leaky ReLU関数を適用\n",
    "                    nn.LeakyReLU(negative_slope=0.2),\n",
    "                ),\n",
    "                # 第4層: (bs, 512, 3, 3) -> (bs, 1, 1, 1)\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        start_ch * 4,  # 入力のチャネル数は128×4\n",
    "                        1,  # フィルター数は1\n",
    "                        3,  # 3×3のフィルター\n",
    "                        1,  # ストライドは1\n",
    "                        0,\n",
    "                    ),  # パディングは0(なし)\n",
    "                    # 最終出力にはシグモイド関数を適用\n",
    "                    nn.Sigmoid(),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        # self.layers = nn.ModuleList(\n",
    "        #     [\n",
    "        #         # 第1層: (bs, 3+num_classes, 32, 32) -> (bs, 128, 16, 16)\n",
    "        #         nn.Sequential(\n",
    "        #             # 畳み込み\n",
    "        #             nn.Conv2d(\n",
    "        #                 in_ch,  # 入力のチャネル数は 3+num_classes\n",
    "        #                 start_ch,  # フィルター数は128\n",
    "        #                 3,  # 4×4のフィルター\n",
    "        #                 1,  # ストライドは2\n",
    "        #                 1,  # 上下左右にサイズ1のパディング\n",
    "        #             ),\n",
    "        #             # LeakyReLU関数を適用\n",
    "        #             # 負の勾配を制御する係数を0.2(デフォルトは0.01)\n",
    "        #             nn.LeakyReLU(negative_slope=0.2),\n",
    "        #         ),\n",
    "        #         # 第2層: (bs, 128, 16, 16) -> (bs, 256, 8, 8)\n",
    "        #         nn.Sequential(\n",
    "        #             # 畳み込み\n",
    "        #             nn.Conv2d(\n",
    "        #                 start_ch,  # 入力のチャネル数は128\n",
    "        #                 start_ch * 2,  # フィルター数は128×2\n",
    "        #                 4,  # 4×4のフィルター\n",
    "        #                 2,  # ストライドは2\n",
    "        #                 1,  # 上下左右にサイズ1のパディング\n",
    "        #             ),\n",
    "        #             # 出力値を正規化する(チャネル数は128×2)\n",
    "        #             nn.BatchNorm2d(start_ch * 2),\n",
    "        #             # LeakyReLU関数を適用\n",
    "        #             nn.LeakyReLU(negative_slope=0.2),\n",
    "        #         ),\n",
    "        #         # 第3層: (bs, 256, 8, 8) -> (bs, 512, 4, 4)\n",
    "        #         nn.Sequential(\n",
    "        #             # 畳み込み\n",
    "        #             nn.Conv2d(\n",
    "        #                 start_ch * 2,  # 入力のチャネル数は128×2\n",
    "        #                 start_ch * 4,  # フィルター数は128×4\n",
    "        #                 4,  # 4×4のフィルター\n",
    "        #                 2,  # ストライドは2\n",
    "        #                 1,  # 上下左右にサイズ1のパディング\n",
    "        #             ),\n",
    "        #             # 出力値を正規化する(チャネル数は128×4)\n",
    "        #             nn.BatchNorm2d(start_ch * 4),\n",
    "        #             # LeakyReLU関数を適用\n",
    "        #             nn.LeakyReLU(negative_slope=0.2),\n",
    "        #         ),\n",
    "        #         # 第4層: (bs, 512, 4, 4) -> (bs, 1024, 4, 4)\n",
    "        #         nn.Sequential(\n",
    "        #             nn.Conv2d(\n",
    "        #                 start_ch * 4,  # 入力のチャネル数は128×4\n",
    "        #                 start_ch * 8,  # フィルター数は1\n",
    "        #                 4,  # 4×4のフィルター\n",
    "        #                 2,  # ストライドは1\n",
    "        #                 1,  # パディングは0(なし)\n",
    "        #             ),\n",
    "        #             # 出力値を正規化する(チャネル数は128×4)\n",
    "        #             nn.BatchNorm2d(start_ch * 8),\n",
    "        #             # LeakyReLU関数を適用\n",
    "        #             nn.LeakyReLU(negative_slope=0.2),\n",
    "        #         ),\n",
    "        #         # 第5層: (bs, 1024, 4, 4) -> (bs, 1, 1, 1)\n",
    "        #         nn.Sequential(\n",
    "        #             nn.Conv2d(\n",
    "        #                 start_ch * 8,  # 入力のチャネル数は128×8\n",
    "        #                 1,  # フィルター数は1\n",
    "        #                 4,  # 4×4のフィルター\n",
    "        #                 1,  # ストライドは1\n",
    "        #                 0,  # パディングは0(なし)\n",
    "        #             ),\n",
    "        #             # 最終出力にはシグモイド関数を適用\n",
    "        #             nn.Sigmoid(),\n",
    "        #         ),\n",
    "        #     ]\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          x: 画像データまたは生成画像\n",
    "        \"\"\"\n",
    "        # 識別器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        # 出力されたテンソルの形状をフラット(bs,)にする\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wxyecq_1nTj1"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"生成器のクラス\n",
    "\n",
    "    Attributes:\n",
    "      layers: Sequentialオブジェクトのリスト\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"生成器のネットワークを構築する\"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        input_dim = 100 + num_classes  # 入力データの次元\n",
    "        out_ch = 128  # 最終層のチャネル数\n",
    "        img_ch = 3  # 生成画像のチャネル数\n",
    "\n",
    "        # 生成器のネットワークを定義する\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                # Layer 1: Project and reshape (bs, input_dim, 1, 1) -> (bs, 1024, 4, 4)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(input_dim, out_ch * 8, 4, 1, 0),\n",
    "                    nn.BatchNorm2d(out_ch * 8),\n",
    "                    nn.ReLU(True),\n",
    "                ),\n",
    "                # Layer 2: (bs, 1024, 4, 4) -> (bs, 512, 8, 8)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(out_ch * 8, out_ch * 4, 4, 2, 1),\n",
    "                    nn.BatchNorm2d(out_ch * 4),\n",
    "                    nn.ReLU(True),\n",
    "                ),\n",
    "                # Layer 3: (bs, 512, 8, 8) -> (bs, 256, 16, 16)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(out_ch * 4, out_ch * 2, 4, 2, 1),\n",
    "                    nn.BatchNorm2d(out_ch * 2),\n",
    "                    nn.ReLU(True),\n",
    "                ),\n",
    "                # Layer 4: (bs, 256, 16, 16) -> (bs, 128, 32, 32)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(out_ch * 2, out_ch, 4, 2, 1),\n",
    "                    nn.BatchNorm2d(out_ch),\n",
    "                    nn.ReLU(True),\n",
    "                ),\n",
    "                # Layer 5: (bs, 128, 32, 32) -> (bs, 3, 32, 32)\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(out_ch, img_ch, 3, 1, 1),\n",
    "                    nn.Tanh(),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"順伝播処理\n",
    "\n",
    "        Parameter:\n",
    "          z: 識別器の出力\n",
    "        \"\"\"\n",
    "        # 生成器のネットワークに入力して順伝播する\n",
    "        for layer in self.layers:\n",
    "            z = layer(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create GAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 重みの初期化を行う関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hgiP3bPGncbM"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    ネットワークの重みを正規分布からサンプリングした値で初期化する\n",
    "\n",
    "    Parameters:\n",
    "    m: ネットワークのインスタンス\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    # 畳み込み層の重み\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)  # 平均0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0)  # バイアスのみ0で初期化\n",
    "    # バッチ正規化層の重み\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)  # 平均1.0、標準偏差0.02の正規分布\n",
    "        m.bias.data.fill_(0)  # バイアスのみ0で初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 生成器をインスタンス化して重みを初期化する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3804,
     "status": "ok",
     "timestamp": 1627730198814,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "f7VJAquMnf36",
    "outputId": "7aff3deb-6e9d-4dc6-c71a-7d5325c56a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [-1, 1024, 4, 4]       1,803,264\n",
      "       BatchNorm2d-2           [-1, 1024, 4, 4]           2,048\n",
      "              ReLU-3           [-1, 1024, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 512, 8, 8]       8,389,120\n",
      "       BatchNorm2d-5            [-1, 512, 8, 8]           1,024\n",
      "              ReLU-6            [-1, 512, 8, 8]               0\n",
      "   ConvTranspose2d-7          [-1, 256, 16, 16]       2,097,408\n",
      "       BatchNorm2d-8          [-1, 256, 16, 16]             512\n",
      "              ReLU-9          [-1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-10          [-1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-11          [-1, 128, 32, 32]             256\n",
      "             ReLU-12          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-13            [-1, 3, 32, 32]           3,459\n",
      "             Tanh-14            [-1, 3, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 12,821,507\n",
      "Trainable params: 12,821,507\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 5.67\n",
      "Params size (MB): 48.91\n",
      "Estimated Total Size (MB): 54.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 生成器をインスタンス化\n",
    "generator = Generator().to(device)\n",
    "# 重みを初期化\n",
    "generator.apply(weights_init)\n",
    "# 生成器のサマリを出力\n",
    "torchsummary.summary(generator, (100 + num_classes, 1, 1))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 識別器をインスタンス化して重みを初期化する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1627730198815,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "yhSIPXkqnmNc",
    "outputId": "f4615728-92f1-4602-d3d0-a2db60cd18b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 16, 16]          26,752\n",
      "         LeakyReLU-2          [-1, 128, 16, 16]               0\n",
      "            Conv2d-3            [-1, 256, 8, 8]         524,544\n",
      "       BatchNorm2d-4            [-1, 256, 8, 8]             512\n",
      "         LeakyReLU-5            [-1, 256, 8, 8]               0\n",
      "            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "         LeakyReLU-8            [-1, 512, 3, 3]               0\n",
      "            Conv2d-9              [-1, 1, 1, 1]           4,609\n",
      "          Sigmoid-10              [-1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,737,601\n",
      "Trainable params: 1,737,601\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.98\n",
      "Params size (MB): 6.63\n",
      "Estimated Total Size (MB): 7.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 識別器をインスタンス化\n",
    "discriminator = Discriminator(num_classes).to(device)\n",
    "# discriminator = Discriminator().to(device)\n",
    "# 重みを初期化\n",
    "discriminator.apply(weights_init)\n",
    "# 識別器のサマリを出力\n",
    "torchsummary.summary(discriminator, (num_classes + 3, 32, 32))  # 入力テンソルの形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Other functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 損失関数とオプティマイザーの設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0XIwXN38nuaA"
   },
   "outputs": [],
   "source": [
    "# 損失関数はバイナリクロスエントロピー誤差\n",
    "criterion = nn.BCELoss()\n",
    "# 識別器のオプティマイザ−を設定\n",
    "# cf. suggested learning rate for original Adam optimizer is 0.001\n",
    "optimizer_ds = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "# 生成器のオプティマイザーを設定\n",
    "optimizer_gn = optim.Adam(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 正解ラベルを One-hot 化する関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "q2qf1mp2nx_g"
   },
   "outputs": [],
   "source": [
    "def encoder(label, device, n_class=10):\n",
    "    \"\"\"\n",
    "    正解ラベルをOne-hot表現に変換する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label: 変換対象の正解ラベル\n",
    "    device: 使用するデバイス\n",
    "    n_class: 分類先のクラス数\n",
    "    \"\"\"\n",
    "    # 対角成分の値が1の対角行列を作成\n",
    "    # 2階テンソル(クラスの数, クラスの数)が作成される\n",
    "    one_hot = torch.eye(n_class, device=device)\n",
    "    # ラベルの値のインデックスのOne-hot表現を抽出し、\n",
    "    # 生成器が入力する(バッチサイズ, クラス数, 1, 1)の形状にして返す\n",
    "    return one_hot[label].view(-1, n_class, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 画像のテンソルとラベルのテンソルを結合する関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BzkqmHPrn2nS"
   },
   "outputs": [],
   "source": [
    "def concat_img_label(image, label, device, n_class=10):\n",
    "    \"\"\"\n",
    "    画像のテンソルとラベルのテンソルを連結して識別器に入力するテンソルを作成する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: 画像データを格納したテンソル(bs, 1, 28, 28)\n",
    "    label: 正解ラベル\n",
    "    device: 使用可能なデバイス\n",
    "    n_class: 分類先のクラス数\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    画像とOne-hot化ラベルを結合したテンソル\n",
    "    (bs, 11, 28, 28)\n",
    "    \"\"\"\n",
    "    # 画像が格納されたテンソルの形状を取得する\n",
    "    bs, ch, h, w = image.shape\n",
    "    # ラベルをOne-hot表現に変換\n",
    "    oh_label = encoder(label, device, n_class)\n",
    "    # 画像のサイズに合わせて正解ラベルを(bs, 10, 28, 28)に拡張する\n",
    "    oh_label = oh_label.expand(bs, n_class, h, w)\n",
    "    # 画像(bs, 1(チャネル), 28, 28)とチャネル方向(dim=1)で結合して戻り値とする\n",
    "    return torch.cat((image, oh_label), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 ノイズのテンソルとラベルのテンソルを連結する関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wudp4WDyn6to"
   },
   "outputs": [],
   "source": [
    "def concat_noise_label(noise: torch.Tensor, label: int, num_classes: int, device: torch.device):\n",
    "    \"\"\"\n",
    "    ノイズのテンソルとラベルのテンソルを連結して生成器に入力するテンソルを作成する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    noise: torch.Tensor\n",
    "        ノイズのテンソル (bs, 100, 1, 1)\n",
    "    label: int\n",
    "        正解ラベル\n",
    "    device: torch.device\n",
    "        使用するデバイス\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    ノイズとOne-hot化ラベルを連結したテンソル\n",
    "    (bs, 100 + num_classes, 1, 1)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes the size of noise as 100.\n",
    "    \"\"\"\n",
    "    assert noise.shape[1] == 100, \"The size of noise must be 100.\"\n",
    "\n",
    "    # ラベルをOne-hot化\n",
    "    oh_label = encoder(label, device, num_classes)\n",
    "    # ノイズ(bs, 100, 1, 1)とOne-hot化ラベルを\n",
    "    # dim=1で連結して戻り値とする\n",
    "    # print(\"noise: {}\".format(noise.shape))\n",
    "    # print(\"oh_label: {}\".format(oh_label.shape))\n",
    "    return torch.cat((noise, oh_label), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 エポックごとの画像生成に使用するノイズのテンソルを作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8LDhMqVRQlWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n",
      "        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        8, 9], device='cuda:0')\n",
      "fixed_noise_label.shape: torch.Size([50, 110, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# ノイズの次元数\n",
    "noise_num = 100\n",
    "\n",
    "# 生成器のエポックごとの画像生成に使用するノイズのテンソルを作成\n",
    "# バッチデータと同じ数だけ作成(bs, 100, 1, 1)\n",
    "fixed_noise = torch.randn(\n",
    "    batch_size, noise_num, 1, 1, device=device  # バッチサイズ  # ノイズの次元100  # 1  # 1\n",
    ")\n",
    "# `num_classes` 個の正解ラベル (0 ~ num_classes-1) をバッチデータの数だけ繰り返す\n",
    "# 配列の要素数はバッチデータの数と同じ\n",
    "assert batch_size // num_classes > 0, \"The batch size must be a multiple of the number of classes.\"\n",
    "fixed_label = [i for i in range(num_classes)] * (batch_size // num_classes)\n",
    "print(fixed_label)\n",
    "# ノイズ用の正解ラベルを1階テンソルに変換: (bs,)\n",
    "fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n",
    "print(fixed_label)\n",
    "# ノイズ(bs, 100, 1, 1)とOne-hot化したラベル (バッチサイズ, クラス数, 1, 1)を\n",
    "# 連結したテンソル (bs, 100+num_classes, 1, 1)を作成\n",
    "fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, num_classes, device)\n",
    "print(\"fixed_noise_label.shape: {}\".format(fixed_noise_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 画像の保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fake_samples(fake_image: torch.Tensor, classes: list, outf: str, epoch: int):\n",
    "    \"\"\"\n",
    "    Save fake samples generated by Generator during training.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fake_image: torch.Tensor\n",
    "        Fake images generated by Generator.\n",
    "    classes: list\n",
    "        List of class names.\n",
    "    outf: str\n",
    "        Path of output directory.\n",
    "    epoch: int\n",
    "        Number of training epoch.\n",
    "    \"\"\"\n",
    "    # 画像を正規化してNumPy配列に変換\n",
    "    fake_image = vutils.make_grid(fake_image.detach(), normalize=True, nrow=10).cpu().numpy()\n",
    "    fake_image = np.transpose(fake_image, (1, 2, 0))\n",
    "\n",
    "    # 画像を表示してラベルを追加\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.imshow(fake_image)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # 各列にラベルを追加\n",
    "    ncols = 10\n",
    "    for i, label in enumerate(classes):\n",
    "        col_position = (fake_image.shape[1] / ncols) * (i + 0.5)\n",
    "        ax.text(col_position, -5, label, ha=\"center\", va=\"bottom\", fontsize=16)\n",
    "\n",
    "    # 画像を保存\n",
    "    plt.savefig(\n",
    "        \"{}/fake_samples_epoch_{:03d}.png\".format(outf, epoch),\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 学習過程の記録\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_learning_history(ds_losses: list[float], gn_losses: list[float], outf: str, show=False):\n",
    "    \"\"\"\n",
    "    Plot the loss history of Discriminator and Generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_losses: list[float]\n",
    "        List of Discriminator loss.\n",
    "    gn_losses: list[float]\n",
    "        List of Generator loss.\n",
    "    outf: str\n",
    "        Path of output directory.\n",
    "    show: bool\n",
    "        If True, show the plot in Jupyter notebook.\n",
    "    \"\"\"\n",
    "    # 損失のプロット\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(ds_losses, label=\"Discriminator Loss\")\n",
    "    plt.plot(gn_losses, label=\"Generator Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"{}/loss_plot.png\".format(outf))\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 464295,
     "status": "ok",
     "timestamp": 1627730795888,
     "user": {
      "displayName": "Main Toshi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhcOIVKs4kKB2bkZdejxUGXGPjbOQBCknqRDw23=s64",
      "userId": "01369137257200460524"
     },
     "user_tz": -540
    },
    "id": "UAYdTff3oCGZ",
    "outputId": "61337de4-9074-4774-f05e-05a21012934a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "(1/1000) ds_loss: 1.784 - gn_loss: 1.867 - true_out: 0.627 - fake_out: 0.655>>0.206\n",
      "(101/1000) ds_loss: 0.335 - gn_loss: 6.043 - true_out: 0.890 - fake_out: 0.154>>0.003\n",
      "(201/1000) ds_loss: 0.160 - gn_loss: 4.017 - true_out: 0.982 - fake_out: 0.110>>0.031\n",
      "(301/1000) ds_loss: 0.256 - gn_loss: 4.592 - true_out: 0.926 - fake_out: 0.068>>0.043\n",
      "(401/1000) ds_loss: 0.543 - gn_loss: 2.951 - true_out: 0.861 - fake_out: 0.217>>0.104\n",
      "(501/1000) ds_loss: 0.049 - gn_loss: 7.333 - true_out: 0.968 - fake_out: 0.011>>0.003\n",
      "(601/1000) ds_loss: 0.072 - gn_loss: 5.040 - true_out: 0.973 - fake_out: 0.038>>0.016\n",
      "(701/1000) ds_loss: 0.008 - gn_loss: 7.566 - true_out: 0.995 - fake_out: 0.002>>0.001\n",
      "(801/1000) ds_loss: 0.066 - gn_loss: 9.060 - true_out: 0.943 - fake_out: 0.000>>0.000\n",
      "(901/1000) ds_loss: 0.278 - gn_loss: 3.943 - true_out: 0.995 - fake_out: 0.172>>0.045\n",
      "Epoch 2/50\n",
      "(1/1000) ds_loss: 0.006 - gn_loss: 6.503 - true_out: 0.998 - fake_out: 0.005>>0.006\n",
      "(101/1000) ds_loss: 0.057 - gn_loss: 9.204 - true_out: 0.954 - fake_out: 0.004>>0.001\n",
      "(201/1000) ds_loss: 0.204 - gn_loss: 5.555 - true_out: 0.901 - fake_out: 0.044>>0.014\n",
      "(301/1000) ds_loss: 0.108 - gn_loss: 4.690 - true_out: 0.994 - fake_out: 0.085>>0.027\n",
      "(401/1000) ds_loss: 0.080 - gn_loss: 5.282 - true_out: 0.974 - fake_out: 0.045>>0.032\n",
      "(501/1000) ds_loss: 0.069 - gn_loss: 3.981 - true_out: 0.994 - fake_out: 0.053>>0.051\n",
      "(601/1000) ds_loss: 0.054 - gn_loss: 6.716 - true_out: 0.993 - fake_out: 0.040>>0.006\n",
      "(701/1000) ds_loss: 0.174 - gn_loss: 2.236 - true_out: 0.982 - fake_out: 0.123>>0.204\n",
      "(801/1000) ds_loss: 0.034 - gn_loss: 5.321 - true_out: 0.996 - fake_out: 0.029>>0.014\n",
      "(901/1000) ds_loss: 0.337 - gn_loss: 4.941 - true_out: 0.871 - fake_out: 0.070>>0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110940/3515492593.py:21: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(figsize=(15, 15))\n",
      "/tmp/ipykernel_110940/2212187069.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "(1/1000) ds_loss: 0.105 - gn_loss: 3.934 - true_out: 0.981 - fake_out: 0.076>>0.056\n",
      "(101/1000) ds_loss: 0.034 - gn_loss: 4.829 - true_out: 0.992 - fake_out: 0.025>>0.015\n",
      "(201/1000) ds_loss: 0.006 - gn_loss: 6.218 - true_out: 0.998 - fake_out: 0.004>>0.006\n",
      "(301/1000) ds_loss: 0.732 - gn_loss: 2.557 - true_out: 0.726 - fake_out: 0.217>>0.142\n",
      "(401/1000) ds_loss: 0.103 - gn_loss: 4.806 - true_out: 0.988 - fake_out: 0.080>>0.014\n",
      "(501/1000) ds_loss: 0.167 - gn_loss: 4.926 - true_out: 0.901 - fake_out: 0.049>>0.017\n",
      "(601/1000) ds_loss: 0.165 - gn_loss: 4.150 - true_out: 0.921 - fake_out: 0.047>>0.034\n",
      "(701/1000) ds_loss: 0.021 - gn_loss: 5.635 - true_out: 0.987 - fake_out: 0.007>>0.010\n",
      "(801/1000) ds_loss: 0.054 - gn_loss: 5.079 - true_out: 0.999 - fake_out: 0.047>>0.016\n",
      "(901/1000) ds_loss: 0.563 - gn_loss: 3.367 - true_out: 0.840 - fake_out: 0.167>>0.079\n",
      "Epoch 4/50\n",
      "(1/1000) ds_loss: 0.156 - gn_loss: 4.237 - true_out: 0.965 - fake_out: 0.092>>0.052\n",
      "(101/1000) ds_loss: 0.258 - gn_loss: 5.092 - true_out: 0.848 - fake_out: 0.046>>0.014\n",
      "(201/1000) ds_loss: 0.285 - gn_loss: 4.319 - true_out: 0.845 - fake_out: 0.063>>0.037\n",
      "(301/1000) ds_loss: 0.423 - gn_loss: 3.731 - true_out: 0.837 - fake_out: 0.161>>0.081\n",
      "(401/1000) ds_loss: 0.329 - gn_loss: 2.970 - true_out: 0.863 - fake_out: 0.124>>0.090\n",
      "(501/1000) ds_loss: 0.746 - gn_loss: 8.584 - true_out: 0.581 - fake_out: 0.001>>0.000\n",
      "(601/1000) ds_loss: 0.157 - gn_loss: 3.455 - true_out: 0.990 - fake_out: 0.123>>0.072\n",
      "(701/1000) ds_loss: 0.175 - gn_loss: 4.253 - true_out: 0.944 - fake_out: 0.100>>0.029\n",
      "(801/1000) ds_loss: 0.675 - gn_loss: 2.978 - true_out: 0.875 - fake_out: 0.339>>0.106\n",
      "(901/1000) ds_loss: 0.771 - gn_loss: 2.848 - true_out: 0.803 - fake_out: 0.253>>0.162\n",
      "Epoch 5/50\n",
      "(1/1000) ds_loss: 0.264 - gn_loss: 3.131 - true_out: 0.963 - fake_out: 0.168>>0.105\n",
      "(101/1000) ds_loss: 0.169 - gn_loss: 3.495 - true_out: 0.931 - fake_out: 0.077>>0.057\n",
      "(201/1000) ds_loss: 0.369 - gn_loss: 2.871 - true_out: 0.896 - fake_out: 0.188>>0.101\n",
      "(301/1000) ds_loss: 0.126 - gn_loss: 4.187 - true_out: 0.981 - fake_out: 0.089>>0.042\n",
      "(401/1000) ds_loss: 0.097 - gn_loss: 4.783 - true_out: 0.966 - fake_out: 0.052>>0.031\n",
      "(501/1000) ds_loss: 0.220 - gn_loss: 4.193 - true_out: 0.874 - fake_out: 0.034>>0.053\n",
      "(601/1000) ds_loss: 0.445 - gn_loss: 2.873 - true_out: 0.936 - fake_out: 0.247>>0.136\n",
      "(701/1000) ds_loss: 0.062 - gn_loss: 5.949 - true_out: 0.996 - fake_out: 0.046>>0.013\n",
      "(801/1000) ds_loss: 0.537 - gn_loss: 3.208 - true_out: 0.914 - fake_out: 0.283>>0.096\n",
      "(901/1000) ds_loss: 1.241 - gn_loss: 2.739 - true_out: 0.580 - fake_out: 0.179>>0.183\n",
      "Epoch 6/50\n",
      "(1/1000) ds_loss: 0.230 - gn_loss: 3.801 - true_out: 0.916 - fake_out: 0.090>>0.055\n",
      "(101/1000) ds_loss: 0.178 - gn_loss: 3.992 - true_out: 0.954 - fake_out: 0.094>>0.059\n",
      "(201/1000) ds_loss: 0.400 - gn_loss: 2.457 - true_out: 0.888 - fake_out: 0.203>>0.135\n",
      "(301/1000) ds_loss: 0.138 - gn_loss: 3.477 - true_out: 0.940 - fake_out: 0.060>>0.052\n",
      "(401/1000) ds_loss: 1.114 - gn_loss: 2.370 - true_out: 0.647 - fake_out: 0.307>>0.178\n",
      "(501/1000) ds_loss: 0.751 - gn_loss: 2.322 - true_out: 0.956 - fake_out: 0.438>>0.162\n",
      "(601/1000) ds_loss: 0.262 - gn_loss: 3.468 - true_out: 0.856 - fake_out: 0.072>>0.083\n",
      "(701/1000) ds_loss: 0.600 - gn_loss: 2.530 - true_out: 0.849 - fake_out: 0.283>>0.154\n",
      "(801/1000) ds_loss: 1.545 - gn_loss: 1.333 - true_out: 0.505 - fake_out: 0.391>>0.376\n",
      "(901/1000) ds_loss: 1.842 - gn_loss: 1.762 - true_out: 0.411 - fake_out: 0.317>>0.247\n",
      "Epoch 7/50\n",
      "(1/1000) ds_loss: 1.762 - gn_loss: 3.045 - true_out: 0.406 - fake_out: 0.229>>0.102\n",
      "(101/1000) ds_loss: 0.209 - gn_loss: 3.933 - true_out: 0.914 - fake_out: 0.093>>0.055\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "n_epoch = 50  # 学習回数\n",
    "\n",
    "# 画像の保存先のパス\n",
    "# パスは環境に合わせて書き換えることが必要\n",
    "outf = \"/home/a6000/github/pilot-GAN/C-DCGAN_weak/result\"\n",
    "\n",
    "# list to save the loss history\n",
    "ds_losses = []\n",
    "gn_losses = []\n",
    "\n",
    "# save initial image (should be random noise)\n",
    "fake_image = generator(fixed_noise_label)  # (bs, 100+num_classes, 1, 1)\n",
    "save_fake_samples(fake_image, train_dataset.classes, outf, 0)\n",
    "\n",
    "# 学習のループ\n",
    "for epoch in range(n_epoch):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, n_epoch))\n",
    "\n",
    "    # バッチデータのループ(ステップ)\n",
    "    for itr, data in enumerate(dataloader):\n",
    "        # ミニバッチのすべての画像を取得\n",
    "        real_image = data[0].to(device)\n",
    "        # ミニバッチのすべての正解ラベルを取得\n",
    "        real_label = data[1].to(device)\n",
    "        # 画像とOne-hot化したラベルを連結したテンソルを取得\n",
    "        # (bs, 1+num_classes, 28, 28)\n",
    "        real_image_label = concat_img_label(\n",
    "            real_image, real_label, n_class=num_classes, device=device\n",
    "        )  # 画像  # 正解ラベル\n",
    "        # 標準正規分布からノイズを生成: 出力(bs, 100, 1, 1)\n",
    "        noise = torch.randn(\n",
    "            batch_size, noise_num, 1, 1, device=device  # バッチサイズ  # ノイズの次元100  # 1  # 1\n",
    "        )\n",
    "        # フェイク画像用の正解ラベルを生成: 出力(bs,)\n",
    "        fake_label = torch.randint(\n",
    "            num_classes,  # 0 ～ num_classes-1 のラベルを生成\n",
    "            (batch_size,),  # バッチデータの数だけ生成\n",
    "            dtype=torch.long,\n",
    "            device=device,\n",
    "        )\n",
    "        # ノイズとフェイクのラベルを連結: (bs, 110, 1, 1)\n",
    "        fake_noise_label = concat_noise_label(\n",
    "            noise, fake_label, num_classes, device  # (bs, 100, 1, 1)  # (bs,)\n",
    "        )\n",
    "        # オリジナル画像に対する識別信号の正解値「1」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        real_target = torch.full((batch_size,), 1.0, device=device)\n",
    "        # 生成画像に対する識別信号の正解値「0」で初期化した\n",
    "        # (bs,)の形状のテンソルを生成\n",
    "        fake_target = torch.full((batch_size,), 0.0, device=device)\n",
    "\n",
    "        # -----識別器の学習-----\n",
    "        # 識別器の誤差の勾配を初期化\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # 識別器に画像とラベルのセットを入力して識別信号を出力\n",
    "        output = discriminator(real_image_label)\n",
    "        # オリジナル画像に対する識別値の損失を取得\n",
    "        ds_real_err = criterion(output, real_target)\n",
    "        # 1ステップ(1バッチ)におけるオリジナル画像の識別信号の平均\n",
    "        true_dsout_mean = output.mean().item()\n",
    "\n",
    "        # ノイズとフェイクのラベルを生成器に入力してフェイク画像を生成\n",
    "        # (bs, 1, 28, 28)\n",
    "        fake_image = generator(fake_noise_label)  # (bs, 110, 1, 1)\n",
    "        # フェイク画像とフェイクのラベルを連結: (bs, 11, 28, 28)\n",
    "        fake_image_label = concat_img_label(\n",
    "            fake_image, fake_label, n_class=num_classes, device=device  # (bs, 1, 28, 28)  # (bs,)\n",
    "        )\n",
    "\n",
    "        # フェイク画像とフェイクラベルを識別器に入力して識別信号を出力\n",
    "        output = discriminator(fake_image_label.detach())\n",
    "        # output = discriminator(fake_image)\n",
    "        # フェイク画像を偽と判定できない場合の損失\n",
    "        ds_fake_err = criterion(\n",
    "            output, fake_target  # フェイク画像の識別信号\n",
    "        )  # 正解ラベル(偽物の0)\n",
    "        # フェイク画像の識別信号の平均\n",
    "        fake_dsout_mean1 = output.mean().item()\n",
    "        # オリジナル画像とフェイク画像に対する識別の損失を合計して\n",
    "        # 識別器としての損失を求める\n",
    "        ds_err = ds_real_err + ds_fake_err\n",
    "\n",
    "        # 識別器全体の誤差を逆伝播\n",
    "        ds_err.backward()\n",
    "        # 判別器の重みのみを更新(生成器は更新しない)\n",
    "        optimizer_ds.step()\n",
    "\n",
    "        # -----生成器の学習-----\n",
    "        # 生成器の誤差の勾配を初期化\n",
    "        generator.zero_grad()\n",
    "        # 更新後の識別器に再度フェイク画像とフェイクラベルを入力して識別信号を取得\n",
    "        output = discriminator(fake_image_label)\n",
    "        # フェイク画像をオリジナル画像と誤認できない場合の損失\n",
    "        gn_err = criterion(\n",
    "            output, real_target  # フェイク画像の識別信号\n",
    "        )  # 誤認させるのが目的なので正解ラベルは1\n",
    "        # 更新後の識別器の誤差を逆伝播\n",
    "        gn_err.backward()\n",
    "        # 更新後の識別器のフェイク画像に対する識別信号の平均\n",
    "        fake_dsout_mean2 = output.mean().item()\n",
    "        # 生成器の重みを更新後の識別誤差の勾配で更新\n",
    "        optimizer_gn.step()\n",
    "\n",
    "        # 100ステップごとに出力\n",
    "        if itr % 100 == 0:\n",
    "            # figure of learning history\n",
    "            ds_losses.append(ds_err.item())\n",
    "            gn_losses.append(gn_err.item())\n",
    "            save_learning_history(ds_losses, gn_losses, outf)\n",
    "\n",
    "            # output to console\n",
    "            print(\n",
    "                \"({}/{}) ds_loss: {:.3f} - gn_loss: {:.3f} - true_out: {:.3f} - fake_out: {:.3f}>>{:.3f}\".format(\n",
    "                    itr + 1,  # ステップ数(イテレート回数)\n",
    "                    len(dataloader),  # ステップ数(1エポックのバッチ数)\n",
    "                    ds_err.item(),  # 識別器の損失\n",
    "                    gn_err.item(),  # フェイクをオリジナルと誤認しない損失\n",
    "                    true_dsout_mean,  # オリジナル画像の識別信号の平均\n",
    "                    fake_dsout_mean1,  # フェイク画像の識別信号の平均\n",
    "                    fake_dsout_mean2,  # 更新後識別器のフェイクの識別信号平均\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # 学習開始直後にオリジナル画像を保存する\n",
    "        if epoch == 0 and itr == 0:\n",
    "            vutils.save_image(\n",
    "                real_image, \"{}/real_samples.png\".format(outf), normalize=True, nrow=10\n",
    "            )\n",
    "\n",
    "    # 確認用画像の生成\n",
    "    # 1エポック終了ごとに確認用の生成画像を生成する\n",
    "    fake_image = generator(fixed_noise_label)\n",
    "    save_fake_samples(fake_image, train_dataset.classes, outf, epoch + 1)\n",
    "\n",
    "save_learning_history(ds_losses, gn_losses, outf, show=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoE4FLY/QwY2OJzNGYCtES",
   "collapsed_sections": [],
   "mount_file_id": "1yyNwZ-FkZlnt0F5_clgAxZb33ujtaxV9",
   "name": "C-GAN_MNIST_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
